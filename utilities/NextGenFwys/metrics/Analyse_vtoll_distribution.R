
# ----------------------------------------------------------------------------------------------------------------
# Analyze_vtoll_distribution.r
#
# This script summarizes value (+ cordon) toll distribution
#
# Inputs:   
# %TARGET_DIR%\updated_output\trips_with_detailed_cost.rdata
# (generated by travel-model-one/utilities/NextGenFwys/metrics/travel-cost-by-income-driving-households.r)
#
# Outputs:  
# (1) %TARGET_DIR%\updated_output\hhld_vtoll_stats.csv, which contains the variables:
# -- annual_vtoll_mean:              annualized average household value toll cost 
# -- annual_vtoll_median: 
# -- annual_vtoll_p90
# -- annual_vtoll_max
# -- annual_vtoll_dropped0s_min,
# -- annual_vtoll_dropped0s_mean
# -- percentage_zero
#
# (2) %TARGET_DIR%\updated_output\hhld_vtoll_percentile_plot.jpg.
# The x-axis is percentiles; the y-axis is household annual value toll cost. 
# 
# (2) %TARGET_DIR%\updated_output\hhld_vtoll_percentiles.csv, which contains the variables:
# -- vtollPercentile
# -- vtollValue
# (this file is created in case we want to create the percentile plot in PowerPoint or Excel)
#
# (3) %TARGET_DIR%\updated_output\hhld_vtoll_freqTable.csv, which contains the variables: 
# -- vtoll_bin
# -- vtoll_lower_bound
# -- vtoll_upper_bound
# -- num_hhld
# -- percent_hhld
#
# (additional outputs need to be documented)
# for the AG10 slide deck, I used the results from the outputs hhld_vNctoll_stats.csv, hhld_vNctoll_stats_incQ1.csv and hhld_vNctoll_percentiles.csv
#
# ----------------------------------------------------------------------------------------------------------------

library(dplyr)
library(knitr) # for the kable function that creates well-formatted tables 

# paths if running this script from command prompt
TARGET_DIR   <- Sys.getenv("TARGET_DIR")  # The location of the input files
TARGET_DIR   <- gsub("\\\\","/",TARGET_DIR) # switch slashes around

# for NGF Round 1, the TARGET_DIR are: 
#TARGET_DIR = "//MODEL2-C/Model2C-Share/Projects/2035_TM152_NGF_NP10_Path4_02"       # new numbering: P1
#TARGET_DIR = "//MODEL3-C/Model3C-Share/Projects/2035_TM152_NGF_NP10_Path3a_02"      # new numbering: 2A
#TARGET_DIR = "//MODEL3-D/Model3D-Share/Projects/2035_TM152_NGF_NP10_Path3b_02"       # new numbering: 2B
#TARGET_DIR = "//MODEL3-A/Model3A-Share/Projects/2035_TM152_NGF_NP10_Path1a_02"      # new numbering: 3A
#TARGET_DIR = "//MODEL3-B/Model3B-Share/Projects/2035_TM152_NGF_NP10_Path1b_02"      # new numbering: P3B
#TARGET_DIR = "//MODEL2-D/Model2D-Share/Projects/2035_TM152_NGF_NP10_Path2a_02_10pc" # new numbering: P4A
#TARGET_DIR = "//MODEL3-D/Model3D-Share/Projects/2035_TM152_NGF_NP10_Path2b_02_10pc" # new numbering: P4B

# read inputs
detailedCost_file <- file.path(TARGET_DIR, "updated_output", "trips_with_detailed_cost.rdata")
load(detailedCost_file)

# The dataframe already has a name - it's trips
# Rename dataframe with a df_ prefix to make it easier to remember it is a data frame
df_trips <- trips
rm(trips)

# Note that the input file trips_with_detailed_cost.rdata is a 50% sample
SAMPLESHARE  <- 0.5

#-----------------------------------------------
# Analysis at the trip level
# Keeping this brief for now - as hhld level analysis is more consistent with the metric Affordable 1
# No output tables are generated from the trip level analysis for now! 
#-----------------------------------------------

# note: the values in value_toll came directly from the skims, so they are in the unit of 2000 cents
df_trip_vtoll_freqTable <- df_trips %>%
  filter(is.finite(value_toll)) %>% # note that the value_toll variables has some NAs
  # The bins: The first bin captures the zeroes. The second set of bins range from 0.000001 to 2000 with an increment of 200. The last bin catches everything bigger than 2000.
  mutate(bin = cut(
    value_toll,
    breaks = c(-Inf, seq(0, 0, 1), seq(0.000001, 1000, 100), Inf),
    include.lowest = TRUE,
    right = FALSE
  )) %>%
  count(bin, sort = FALSE)%>%
  mutate(percent_hhld = prop.table(n) * 100) %>%
  mutate(vtoll_lower_bound = as.numeric(sub("\\[([^,]+).*", "\\1", bin)),
         vtoll_upper_bound = as.numeric(sub("[^,]+,([^\\)]+).*", "\\1", bin)))

# note that the input file is a sample (typically at 50% in iter3) so the frequency n should be divided by sampleshare
df_trip_vtoll_freqTable$n=df_trip_vtoll_freqTable$n/SAMPLESHARE

# print the frequency table to the console
print("Frequency Table -- cell values represent the number of trips falling within a certain value_toll bin")
kable(df_trip_vtoll_freqTable, format = "markdown")


# ---
# sidebar: look at the non-finite values in the variable value_toll
df_non_finite_values <- df_trips %>%
  filter(!is.finite(value_toll)) %>%
  select(value_toll)
df_unique_values <- unique(df_non_finite_values$value_toll)
print(df_unique_values)
# all the non-finite values are NAs
# I wonder what the difference is between NA and 0
# ---

# Lots of trips with 0 vtoll. It's not surprising because the trip table includes all modes.
# focus on driving only households
df_DrivingOnly <- df_trips %>%
  filter(hhld_travel == "auto_no_transit")
df_trip_vtoll_freqTable_DrivingHhld <- df_DrivingOnly %>%
  filter(is.finite(value_toll)) %>% # note that the value_toll variables has some NAs
  # The bins: The first bin captures the zeroes. The second set of bins range from 0.000001 to 1000 with an increment of 100. The last bin catches everything bigger than 1000.
  mutate(bin = cut(
    value_toll,
    breaks = c(-Inf, seq(0, 0, 1), seq(0.000001, 1000, 100), Inf),
    include.lowest = TRUE,
    right = FALSE
  )) %>%
  count(bin, sort = FALSE)%>%
  mutate(percent_hhld = prop.table(n) * 100) %>%
  mutate(vtoll_lower_bound = as.numeric(sub("\\[([^,]+).*", "\\1", bin)),
         vtoll_upper_bound = as.numeric(sub("[^,]+,([^\\)]+).*", "\\1", bin)))

# note that the input file is a sample (typically at 50% in iter3) so the frequency n should be divided by sampleshare
df_trip_vtoll_freqTable_DrivingHhld$n = df_trip_vtoll_freqTable_DrivingHhld$n/SAMPLESHARE

# print the frequency table to the console
print("Frequency Table -- cell values represent the number of trips falling within a certain value_toll bin, for driving household only")
kable(df_trip_vtoll_freqTable_DrivingHhld, format = "markdown")

#-----------------------------------------------
# Analysis at the household level
#-----------------------------------------------

df_hhldCosts <- df_trips %>%
  group_by(hh_id) %>%
  summarise(
    hhld_incQ              = first(incQ),
    hhld_incQ_label        = first(incQ_label),
    hhld_income            = first(income),
    hhld_autos             = first(autos),
    home_taz               = first(home_taz),
    hhld_travel            = first(hhld_travel),
    hhld_trips             = first(hhld_trips),
    hhld_auto_seg_trips    = first(hhld_auto_seg_trips),
    hhld_transit_seg_trips = first(hhld_transit_seg_trips),
    total_parking_cost     = sum(totalParkingCost, na.rm = TRUE),
    total_auto_op_cost     = sum(auto_op_cost, na.rm = TRUE),
    total_bridge_toll      = sum(bridge_toll, na.rm = TRUE),
    total_cordon_toll      = sum(cordon_toll, na.rm = TRUE),
    total_value_toll       = sum(value_toll, na.rm = TRUE),
    total_fare             = sum(fare, na.rm = TRUE),
    total_drv_trn_op_cost  = sum(drv_trn_op_cost, na.rm = TRUE),
    total_taxitnc_cost     = sum(taxitnc_cost, na.rm = TRUE)
  )


# ------------------------------------------
# annualize, convert unit to dollars, convert unit from 2000$ to 2023$
# ------------------------------------------

# annualization and inflation factors:
INFLATION_22_23 <- 1.03 # assumption
INFLATION_00_22 <- 327.06 / 180.20 # source: https://github.com/BayAreaMetro/modeling-website/wiki/InflationAssumptions
INFLATION_00_23 <- INFLATION_00_22 * INFLATION_22_23
N_DAYS_PER_YEAR <- 300 #source: https://github.com/BayAreaMetro/travel-model-one/blob/master/utilities/NextGenFwys/metrics/ngfs_metrics.py

df_hhldCosts <- df_hhldCosts %>%
  mutate(
    annual_parking_cost    = total_parking_cost    * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_auto_op_cost    = total_auto_op_cost    * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_bridge_toll     = total_bridge_toll     * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_cordon_toll     = total_cordon_toll     * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_value_toll      = total_value_toll      * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_fare            = total_fare            * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_drv_trn_op_cost = total_drv_trn_op_cost * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_taxitnc_cost    = total_taxitnc_cost    * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23
  )


# ------------------------------------------
# add variables related to ownership costs
#   ownership + finance
#   insurance
#   registration/taxes
# ------------------------------------------
# Average Annual Costs of Driving a Car in 2020$
# Same assumptions were used in the NGFS metric script (https://github.com/BayAreaMetro/travel-model-one/blob/master/utilities/NextGenFwys/metrics/ngfs_metrics.py)
# Source: AAA Driving Costs 2020; mid-size sedan
# \Box\NextGen Freeways Study\04 Engagement\02_Stakeholder Engagement\Advisory Group\Meeting 02 - Apr 2022 Existing Conditions\NGFS_Advisory Group Meeting 2_Apr2022.pptx
AUTO_OWNERSHIP_COST_2020D           <- 3400
AUTO_INSURANCE_COST_2020D           <- 1250
AUTO_FINANCE_COST_2020D             <- 680
AUTO_REGISTRATION_TAXES_COST_2020D  <- 730
INFLATION_00_20                     <- 300.08 / 180.20 # source: https://github.com/BayAreaMetro/modeling-website/wiki/InflationAssumptions


df_hhldCosts <- df_hhldCosts %>%
  mutate(
    annual_auto_fixed_costs = hhld_autos *(AUTO_OWNERSHIP_COST_2020D + AUTO_FINANCE_COST_2020D + AUTO_FINANCE_COST_2020D + AUTO_REGISTRATION_TAXES_COST_2020D ) / INFLATION_00_20 * INFLATION_00_23
)

OUTFILE0 <- file.path(TARGET_DIR, "updated_output", "hhldCosts.csv")
write.csv(df_hhldCosts, OUTFILE0, row.names = FALSE)
# ------------------------------------------
# get statistics of annual_value_toll
# ------------------------------------------
annual_vtoll_mean <- mean(df_hhldCosts$annual_value_toll)
annual_vtoll_median <- median(df_hhldCosts$annual_value_toll)
annual_vtoll_p90 <- quantile(df_hhldCosts$annual_value_toll, 0.9)
annual_vtoll_max <- max(df_hhldCosts$annual_value_toll)

# Filter out records with annual_value_toll equals to 0
df_hhldCosts_no0vtoll <- df_hhldCosts %>%
  filter(annual_value_toll != 0)
# Find the minimum value of annual_value_toll
annual_vtoll_dropped0s_min <- min(df_hhldCosts_no0vtoll$annual_value_toll)
annual_vtoll_dropped0s_mean <- mean(df_hhldCosts_no0vtoll$annual_value_toll)

# Calculate the percentage of records with annual_value_toll equals to 0
num_zeros <- sum(df_hhldCosts$annual_value_toll == 0)
total_records <- nrow(df_hhldCosts)
percentage_zero <- (num_zeros / total_records) * 100

# print to console
annual_vtoll_mean
annual_vtoll_median
annual_vtoll_p90
annual_vtoll_max
annual_vtoll_dropped0s_min
annual_vtoll_dropped0s_mean
percentage_zero

df_vtoll_stats <- data.frame(
  annual_vtoll_mean,
  annual_vtoll_median,
  annual_vtoll_p90,
  annual_vtoll_max,
  annual_vtoll_dropped0s_min,
  annual_vtoll_dropped0s_mean,
  percentage_zero
)

# export
OUTFILE1 <- file.path(TARGET_DIR, "updated_output", "hhld_vtoll_stats.csv")
write.csv(df_vtoll_stats , OUTFILE1, row.names = FALSE)

# plot it
# Calculate percentiles
vtoll_percentiles <- seq(0, 100, 1)
vtoll_values     <- quantile(df_hhldCosts$annual_value_toll, probs = vtoll_percentiles/100)

jpeg(file.path(TARGET_DIR, "updated_output","hhld_vtoll_percentile_plot.jpg"))
plot(vtoll_percentiles, vtoll_values, type = "o", xlab = "Percentile", ylab = "annual_value_toll", main = "Percentile vs. annual_value_toll")
# Save and close the JPEG file
dev.off()

# Create new data frame for export, for plotting in PPT or Excel
df_vtoll_percentiles <- data.frame(vtollPercentile = vtoll_percentiles, vtollValue = vtoll_values)

# export
OUTFILE2 <- file.path(TARGET_DIR, "updated_output", "hhld_vtoll_percentiles.csv")
write.csv(df_vtoll_percentiles , OUTFILE2, row.names = FALSE)

# ------------------------------------------
# frequency table of annual_value_toll
# ------------------------------------------

df_vtoll_freqTable <- df_hhldCosts %>%
  # The bins: The first bin captures the zeroes. The second set of bins range from 0.000001 to 2000 with an increment of 200. The last bin catches everything bigger than 2000.
  mutate(bin = cut(
    annual_value_toll,
    breaks = c(-Inf, seq(0, 0, 1), seq(0.000001, 2200, 200), Inf),
    include.lowest = TRUE,
    right = FALSE
  )) %>%
  count(bin, sort = FALSE)%>%
  mutate(percent_hhld = prop.table(n) * 100) %>%
  mutate(vtoll_lower_bound = as.numeric(sub("\\[([^,]+).*", "\\1", bin)),
         vtoll_upper_bound = as.numeric(sub("[^,]+,([^\\)]+).*", "\\1", bin)))

# print the frequency table to console
print("Frequency Table -- cell values represent the number of households falling within a certain annual_value_toll bin")
kable(df_vtoll_freqTable, format = "markdown")

# rename the variables to improve clarity
df_vtoll_freqTable <- df_vtoll_freqTable %>%
  rename(vtoll_bin = bin)

# somehow "rename" doesn't work for "n"
# The error was: no applicable method for 'rename' applied to an object of class "function"
# but the following code works:
colnames(df_vtoll_freqTable)[colnames(df_vtoll_freqTable) == "n"] <- "num_hhld"

# accounting for the fact that the input file is a sample (typically at 50% in iter 3)
df_vtoll_freqTable$num_hhld = df_vtoll_freqTable$num_hhld/SAMPLESHARE

# reorder the columns
df_vtoll_freqTable <- df_vtoll_freqTable %>%
  select(vtoll_bin, vtoll_lower_bound, vtoll_upper_bound, num_hhld, percent_hhld)

# export
OUTFILE3 <-file.path(TARGET_DIR, "updated_output", "hhld_vtoll_freqTable.csv")
write.csv(df_vtoll_freqTable , OUTFILE3, row.names = FALSE)

# -------------------------------------------------------------------------
# output a more aggregate version of the vtoll frequency table
# -------------------------------------------------------------------------
df_vtoll_freqTable_SimpleGroups <- df_hhldCosts %>%
  mutate(bin = cut(
    annual_value_toll,
    breaks = c(-Inf, seq(0, 0, 1), seq(0.000001, 1600, 800), Inf),
    #labels = c("No toll cost", "Up to $800", "Above $800"),
    include.lowest = TRUE,
    right = FALSE
  )) %>%
  count(bin, sort = FALSE) %>%
  mutate(percent_hhld = prop.table(n) * 100) %>%
  mutate(vtoll_lower_bound = as.numeric(sub("\\[([^,]+).*", "\\1", bin)),
         vtoll_upper_bound = as.numeric(sub("[^,]+,([^\\)]+).*", "\\1", bin)))

# print the frequency table to console
print("Frequency Table -- cell values represent the number of households falling within a certain (simplified) annual_value_toll bin")
kable(df_vtoll_freqTable_SimpleGroups, format = "markdown")

# rename the variables to improve clarity
df_vtoll_freqTable_SimpleGroups <- df_vtoll_freqTable_SimpleGroups %>%
  rename(vtoll_bin = bin)

# somehow "rename" doesn't work for "n"
# The error was: no applicable method for 'rename' applied to an object of class "function"
# but the following code works:
colnames(df_vtoll_freqTable_SimpleGroups)[colnames(df_vtoll_freqTable_SimpleGroups) == "n"] <- "num_hhld"

# accounting for the fact that the input file is a sample (typically at 50% in iter 3)
df_vtoll_freqTable_SimpleGroups$num_hhld = df_vtoll_freqTable_SimpleGroups$num_hhld/SAMPLESHARE

# reorder the columns
df_vtoll_freqTable_SimpleGroups <- df_vtoll_freqTable_SimpleGroups %>%
  select(vtoll_bin, vtoll_lower_bound, vtoll_upper_bound, num_hhld, percent_hhld)

# export
OUTFILE3_SimpleGroups <-file.path(TARGET_DIR, "updated_output", "hhld_vtoll_freqTable_SimpleGroups.csv")
write.csv(df_vtoll_freqTable_SimpleGroups , OUTFILE3_SimpleGroups, row.names = FALSE)


# -------------------------------------------------------------------------
# a new frequency table that combines value tolls and cordon tolls 
# these two tolls are presented together in NGF Round 1
# -------------------------------------------------------------------------
# add a new variable that sums up annual_value_toll and annual_cordon_toll
df_hhldCosts$annual_valueNcordon_toll =  df_hhldCosts$annual_value_toll + df_hhldCosts$annual_cordon_toll

df_vNctoll_freqTable_SimpleGroups <- df_hhldCosts %>%
  mutate(bin = cut(
    annual_valueNcordon_toll,
    breaks = c(-Inf, seq(0, 0, 1), seq(0.000001, 1600, 800), Inf),
    #labels = c("No toll cost", "Up to $800", "Above $800"),
    include.lowest = TRUE,
    right = FALSE
  )) %>%
  count(bin, sort = FALSE) %>%
  mutate(percent_hhld = prop.table(n) * 100) %>%
  mutate(vNctoll_lower_bound = as.numeric(sub("\\[([^,]+).*", "\\1", bin)),
         vNctoll_upper_bound = as.numeric(sub("[^,]+,([^\\)]+).*", "\\1", bin)))

# print the frequency table to console
print("Frequency Table -- cell values represent the number of households falling within a certain (simplified) annual_valueNcordon_toll bin")
kable(df_vNctoll_freqTable_SimpleGroups, format = "markdown")

# rename the variables to improve clarity
df_vNctoll_freqTable_SimpleGroups <- df_vNctoll_freqTable_SimpleGroups %>%
  rename(vNctoll_bin = bin)

# somehow "rename" doesn't work for "n"
# The error was: no applicable method for 'rename' applied to an object of class "function"
# but the following code works:
colnames(df_vNctoll_freqTable_SimpleGroups)[colnames(df_vNctoll_freqTable_SimpleGroups) == "n"] <- "num_hhld"

# accounting for the fact that the input file is a sample (typically at 50% in iter 3)
df_vNctoll_freqTable_SimpleGroups$num_hhld = df_vNctoll_freqTable_SimpleGroups$num_hhld/SAMPLESHARE

# reorder the columns
df_vNctoll_freqTable_SimpleGroups <- df_vNctoll_freqTable_SimpleGroups %>%
  select(vNctoll_bin, vNctoll_lower_bound, vNctoll_upper_bound, num_hhld, percent_hhld)

# export
OUTFILE3_SimpleGroups_vNctoll <-file.path(TARGET_DIR, "updated_output", "hhld_vNctoll_freqTable_SimpleGroups.csv")
write.csv(df_vNctoll_freqTable_SimpleGroups , OUTFILE3_SimpleGroups_vNctoll, row.names = FALSE)

# ------------------------------------------
# get statistics of annual_valueNcordon_toll
# ------------------------------------------
annual_vNctoll_mean   <- mean(df_hhldCosts$annual_valueNcordon_toll)
annual_vNctoll_median <- median(df_hhldCosts$annual_valueNcordon_toll)
annual_vNctoll_p90    <- quantile(df_hhldCosts$annual_valueNcordon_toll, 0.9)
annual_vNctoll_max    <- max(df_hhldCosts$annual_valueNcordon_toll)

# Filter out records with annual_valueNcordon_toll equals to 0
df_hhldCosts_no0vNctoll <- df_hhldCosts %>%
  filter(annual_valueNcordon_toll != 0)
# Find the minimum value of annual_valueNcordon_toll
annual_vNctoll_dropped0s_min <- min(df_hhldCosts_no0vNctoll$annual_valueNcordon_toll)
annual_vNctoll_dropped0s_mean <- mean(df_hhldCosts_no0vNctoll$annual_valueNcordon_toll)
annual_vNctoll_dropped0s_median <- median(df_hhldCosts_no0vNctoll$annual_valueNcordon_toll)
annual_vNctoll_dropped0s_p90 <- quantile(df_hhldCosts_no0vNctoll$annual_valueNcordon_toll, 0.9)

# Calculate the percentage of records with annual_valueNcordon_toll equals to 0
num_zeros <- sum(df_hhldCosts$annual_valueNcordon_toll == 0)
total_records <- nrow(df_hhldCosts)
percentage_zero <- (num_zeros / total_records) * 100

# Calculate the percentage of records with annual_valueNcordon_toll greater than or equal to a threshold number
# The threshold number was set to 800 because: out of all pathways, the highest p90 value was $754 (P4a: All-Lane & Arterial Tolling)
# On July 10, 2023. Anup requested to change it to 700: https://app.asana.com/0/1203274136008809/1205003161397219/f
threshold <- 700
num_paythresholdplus                 <- sum(df_hhldCosts$annual_valueNcordon_toll >= threshold)
percentage_paythresholdplus_outOfTot <- (num_paythresholdplus / total_records ) * 100

# among those who pay more than the threshold, how many of those are low-income
num_paythresholdplus_incQ1                   <- sum(df_hhldCosts$annual_valueNcordon_toll >= threshold & df_hhldCosts$hhld_incQ == 1)
num_incQ1                                    <- sum(df_hhldCosts$hhld_incQ == 1)
annual_vNctoll_paythresholdplus_incQ1        <- sum(df_hhldCosts$annual_valueNcordon_toll[df_hhldCosts$hhld_incQ==1 & df_hhldCosts$annual_valueNcordon_toll> threshold])
percentage_paythresholdplus_incQ1_outOfSubgp <- (num_paythresholdplus_incQ1 / num_paythresholdplus ) * 100
percentage_paythresholdplus_incQ1_outofQ1 <- (num_paythresholdplus_incQ1 / num_incQ1 ) * 100

# among those who pay 90th percentile, how many of those are low-income
num_payP90plus                         <- sum(df_hhldCosts$annual_valueNcordon_toll >= quantile(df_hhldCosts$annual_valueNcordon_toll, 0.9)) # could be a tiny bit different from total_records*0.1
num_payP90plus_incQ1                   <- sum(df_hhldCosts$annual_valueNcordon_toll >= quantile(df_hhldCosts$annual_valueNcordon_toll, 0.9) & df_hhldCosts$hhld_incQ == 1)
percentage_payP90plus_incQ1_outOfSubgp <- (num_payP90plus_incQ1 / num_payP90plus ) * 100
percentage_payP90plus_incQ1_outofQ1    <- (num_payP90plus_incQ1 / num_incQ1 ) * 100


# print to console
annual_vNctoll_mean
annual_vNctoll_median
annual_vNctoll_p90
annual_vNctoll_max
annual_vNctoll_dropped0s_min
annual_vNctoll_dropped0s_mean
annual_vNctoll_dropped0s_median
total_records
num_zeros
num_incQ1
percentage_zero
num_paythresholdplus
percentage_paythresholdplus_outOfTot
annual_vNctoll_paythresholdplus_incQ1
num_paythresholdplus_incQ1
percentage_paythresholdplus_incQ1_outOfSubgp
percentage_paythresholdplus_incQ1_outofQ1
num_payP90plus
num_payP90plus_incQ1
percentage_payP90plus_incQ1_outOfSubgp
percentage_payP90plus_incQ1_outofQ1


df_vNctoll_stats <- data.frame(
  annual_vNctoll_mean,
  annual_vNctoll_median,
  annual_vNctoll_p90,
  annual_vNctoll_max,
  annual_vNctoll_dropped0s_min,
  annual_vNctoll_dropped0s_mean,
  annual_vNctoll_dropped0s_median,
  total_records,
  num_zeros,
  num_incQ1,
  percentage_zero,
  num_paythresholdplus,
  percentage_paythresholdplus_outOfTot,
  annual_vNctoll_paythresholdplus_incQ1,
  num_paythresholdplus_incQ1,
  percentage_paythresholdplus_incQ1_outOfSubgp,
  percentage_paythresholdplus_incQ1_outofQ1,
  num_payP90plus,
  num_payP90plus_incQ1,
  percentage_payP90plus_incQ1_outOfSubgp,
  percentage_payP90plus_incQ1_outofQ1
)

# export
OUTFILE1_vNctoll <- file.path(TARGET_DIR, "updated_output", "hhld_vNctoll_stats.csv")
write.csv(df_vNctoll_stats , OUTFILE1_vNctoll, row.names = FALSE)


# plot it
# Calculate percentiles
vNctoll_percentiles <- seq(0, 100, 1)
vNctoll_values     <- quantile(df_hhldCosts$annual_valueNcordon_toll, probs = vNctoll_percentiles/100)

jpeg(file.path(TARGET_DIR, "updated_output","hhld_vNctoll_percentile_plot.jpg"))
plot(vNctoll_percentiles, vNctoll_values, type = "o", xlab = "Percentile", ylab = "annual_valueNcordon_toll", main = "Percentile vs. annual_valueNcordon_toll")
# Save and close the JPEG file
dev.off()

# Create new data frame for export, for plotting in PPT or Excel
df_vNctoll_percentiles <- data.frame(vNctollPercentile = vNctoll_percentiles, vNctollValue = vNctoll_values)

# export
OUTFILE2_vNctoll <- file.path(TARGET_DIR, "updated_output", "hhld_vNctoll_percentiles.csv")
write.csv(df_vNctoll_percentiles , OUTFILE2_vNctoll, row.names = FALSE)

# plot it for Q1 only
vNctoll_percentiles <- seq(0, 100, 1)
df_hhldCosts_Q1 <- 
  df_hhldCosts %>%
  filter(hhld_incQ == 1)
vNctoll_values      <- quantile(df_hhldCosts_Q1$annual_valueNcordon_toll, probs = vNctoll_percentiles/100)
jpeg(file.path(TARGET_DIR, "updated_output","hhld_vNctoll_percentile_Q1_plot.jpg"))
plot(vNctoll_percentiles, vNctoll_values, type = "o", xlab = "Percentile", ylab = "annual_valueNcordon_toll", main = "Percentile vs. annual_valueNcordon_toll (Q1)")
# Save and close the JPEG file
dev.off()

# Create new data frame for export, for plotting in PPT or Excel
df_vNctoll_percentiles_Q1 <- data.frame(vNctollPercentile = vNctoll_percentiles, vNctollValue = vNctoll_values)

# export
OUTFILE2_vNctoll_Q1 <- file.path(TARGET_DIR, "updated_output", "hhld_vNctoll_percentiles_Q1.csv")
write.csv(df_vNctoll_percentiles_Q1 , OUTFILE2_vNctoll_Q1, row.names = FALSE)

# ------------------------------------------
# focus on the low-income group
# 1. create new frequency table of value tolls + cordon tolls for income group 1
# 2. get statistics on the distribution 
# ------------------------------------------

# create a data frame with households in income group 1 only
df_hhldCosts_incQ1 <- filter(df_hhldCosts, hhld_incQ == 1)

df_vNctoll_freqTable_SimpleGroups_incQ1 <- df_hhldCosts_incQ1 %>%
  mutate(bin = cut(
    annual_valueNcordon_toll,
    breaks = c(-Inf, seq(0, 0, 1), seq(0.000001, 1600, 800), Inf),
    #labels = c("No toll cost", "Up to $800", "Above $800"),
    include.lowest = TRUE,
    right = FALSE
  )) %>%
  count(bin, sort = FALSE) %>%
  mutate(percent_hhld = prop.table(n) * 100) %>%
  mutate(vNctoll_lower_bound = as.numeric(sub("\\[([^,]+).*", "\\1", bin)),
         vNctoll_upper_bound = as.numeric(sub("[^,]+,([^\\)]+).*", "\\1", bin)))

# print the frequency table to console
print("Frequency Table -- cell values represent the number of incQ1 households falling within a certain (simplified) annual_valueNcordon_toll bin")
kable(df_vNctoll_freqTable_SimpleGroups_incQ1, format = "markdown")

# rename the variables to improve clarity
df_vNctoll_freqTable_SimpleGroups_incQ1 <- df_vNctoll_freqTable_SimpleGroups_incQ1 %>%
  rename(vNctoll_bin = bin)

# somehow "rename" doesn't work for "n"
# The error was: no applicable method for 'rename' applied to an object of class "function"
# but the following code works:
colnames(df_vNctoll_freqTable_SimpleGroups_incQ1)[colnames(df_vNctoll_freqTable_SimpleGroups_incQ1) == "n"] <- "num_hhld"

# accounting for the fact that the input file is a sample (typically at 50% in iter 3)
df_vNctoll_freqTable_SimpleGroups_incQ1$num_hhld = df_vNctoll_freqTable_SimpleGroups_incQ1$num_hhld/SAMPLESHARE

# reorder the columns
df_vNctoll_freqTable_SimpleGroups_incQ1 <- df_vNctoll_freqTable_SimpleGroups_incQ1 %>%
  select(vNctoll_bin, vNctoll_lower_bound, vNctoll_upper_bound, num_hhld, percent_hhld)

# export
OUTFILE3_SimpleGroups_vNctoll_incQ1 <-file.path(TARGET_DIR, "updated_output", "hhld_vNctoll_freqTable_SimpleGroups_incQ1.csv")
write.csv(df_vNctoll_freqTable_SimpleGroups_incQ1, OUTFILE3_SimpleGroups_vNctoll_incQ1, row.names = FALSE)

# ------------------------------------------
# get statistics of annual_valueNcordon_toll
# ------------------------------------------
annual_vNctoll_mean   <- mean(df_hhldCosts_incQ1$annual_valueNcordon_toll)
annual_vNctoll_median <- median(df_hhldCosts_incQ1$annual_valueNcordon_toll)
annual_vNctoll_p90    <- quantile(df_hhldCosts_incQ1$annual_valueNcordon_toll, 0.9)
annual_vNctoll_max    <- max(df_hhldCosts_incQ1$annual_valueNcordon_toll)

# Filter out records with annual_valueNcordon_toll equals to 0
df_hhldCosts_incQ1_no0vNctoll <- df_hhldCosts_incQ1 %>%
  filter(annual_valueNcordon_toll != 0)
# Find the minimum value of annual_valueNcordon_toll
annual_vNctoll_dropped0s_min <- min(df_hhldCosts_incQ1_no0vNctoll$annual_valueNcordon_toll)
annual_vNctoll_dropped0s_mean <- mean(df_hhldCosts_incQ1_no0vNctoll$annual_valueNcordon_toll)
annual_vNctoll_dropped0s_median <- median(df_hhldCosts_incQ1_no0vNctoll$annual_valueNcordon_toll)
annual_vNctoll_dropped0s_p90 <- quantile(df_hhldCosts_incQ1_no0vNctoll$annual_valueNcordon_toll, 0.9)

# Calculate the percentage of records with annual_valueNcordon_toll equals to 0
num_zeros <- sum(df_hhldCosts_incQ1$annual_valueNcordon_toll == 0)
total_records <- nrow(df_hhldCosts_incQ1)
percentage_zero <- (num_zeros / total_records) * 100

# print to console
annual_vNctoll_mean
annual_vNctoll_median
annual_vNctoll_p90
annual_vNctoll_max
annual_vNctoll_dropped0s_min
annual_vNctoll_dropped0s_mean
annual_vNctoll_dropped0s_median
annual_vNctoll_dropped0s_p90
percentage_zero

df_vNctoll_stats_incQ1 <- data.frame(
  annual_vNctoll_mean,
  annual_vNctoll_median,
  annual_vNctoll_p90,
  annual_vNctoll_max,
  annual_vNctoll_dropped0s_min,
  annual_vNctoll_dropped0s_mean,
  annual_vNctoll_dropped0s_median,
  annual_vNctoll_dropped0s_p90,
  percentage_zero
)

# export
OUTFILE1_vNctoll_incQ1 <- file.path(TARGET_DIR, "updated_output", "hhld_vNctoll_stats_incQ1.csv")
write.csv(df_vNctoll_stats_incQ1 , OUTFILE1_vNctoll_incQ1, row.names = FALSE)



# ------------------------------------------
# calculate transportation costs as a share of household income (Affordable 1)
# ------------------------------------------
df_hhldCosts <- df_hhldCosts %>%
  mutate(
    annual_total_transportation_costs = annual_auto_fixed_costs + 
                                           annual_parking_cost +
                                           annual_auto_op_cost +
                                           annual_bridge_toll +
                                           annual_cordon_toll +
                                           annual_value_toll +
                                           annual_fare +
                                           annual_drv_trn_op_cost
)
# exclude annual_taxitnc_cost as the annualization factor may not be suitable for taxi and tnc costs
# discussed in Asana: https://app.asana.com/0/0/1204565188037914/f

df_hhldCosts <- df_hhldCosts %>%
  mutate(
    tcosts_as_share_of_hhldinc =  annual_total_transportation_costs / hhld_income
)


# ---
# There are lots of NaN or NA. Need to look at the frequency table.
# Frequency table of transportation costs as a share of household income
# --- 

df_tCostVsInc_freqTable <- df_hhldCosts %>%
  # The bins: The first bin captures the zeroes. The second set of bins range from 0.000001 to 10 with an increment of 1. 
  # The third set of bins range from 10 to 100 with an increment of 10. The last bin catches everything bigger than 100.
  mutate(bin = cut(
    tcosts_as_share_of_hhldinc,
    breaks = c(-Inf, seq(0, 0, 1), seq(0.000001, 100, 10), Inf),
    include.lowest = TRUE,
    right = FALSE
  )) %>%
  count(bin, sort = FALSE)%>%
  mutate(percentage = prop.table(n) * 100) %>%
  mutate(lower_bound = as.numeric(sub("\\[([^,]+).*", "\\1", bin)),
         upper_bound = as.numeric(sub("[^,]+,([^\\)]+).*", "\\1", bin)))

# accounting for the fact that the input file is a sample (typically at 50% in iter 3)
df_tCostVsInc_freqTable$n = df_tCostVsInc_freqTable$n/SAMPLESHARE

# print the frequency table to console
print("Frequency Table of transportation costs as a share of household income (Affordable 1) -- call values represent number of households")
kable(df_tCostVsInc_freqTable, format = "markdown")

# not exporting this one because the data needs to be cleaned

# ------------------------------------------
# Clean out the data so no households have negative or zero income
# ------------------------------------------

# Filter out households negative and zero income
df_hhldCosts_NoNegOrZeroInc <- df_hhldCosts %>%
  filter(hhld_income > 0)

# regenerate the frequency table
df_tCostVsInc_NoNegOrZeroInc_freqTable <- df_hhldCosts_NoNegOrZeroInc %>%
  # The bins: The first bin captures the zeroes. The second set of bins range from 0.000001 to 1 with an increment of 0.1.
  # The third set of bins range from 1 to 10 with an increment of 1. The last bin catches anything bigger than 100.
  mutate(bin = cut(
    tcosts_as_share_of_hhldinc,
    breaks = c(-Inf, seq(0, 0, 1), seq(0.000001, 1, 0.1), seq(1, 10, 1), Inf),
    include.lowest = TRUE,
    right = FALSE
  )) %>%
  count(bin, sort = FALSE)%>%
  mutate(percentage = prop.table(n) * 100) %>%
  mutate(lower_bound = as.numeric(sub("\\[([^,]+).*", "\\1", bin)),
         upper_bound = as.numeric(sub("[^,]+,([^\\)]+).*", "\\1", bin)))

# accounting for the fact that the input file is a sample (typically at 50% in iter 3)
df_tCostVsInc_NoNegOrZeroInc_freqTable$n = df_tCostVsInc_NoNegOrZeroInc_freqTable$n/SAMPLESHARE

# reorder the columns
df_tCostVsInc_NoNegOrZeroInc_freqTable <- df_tCostVsInc_NoNegOrZeroInc_freqTable %>%
  select(bin, lower_bound, upper_bound, n, percentage)

# print the frequency table to console
print("Frequency Table of transportation costs as a share of household income (Affordable 1) -- call values represent number of households. Note that negative or zero incomes are dropped")
kable(df_tCostVsInc_NoNegOrZeroInc_freqTable, format = "markdown")

# export
OUTFILE4 <-file.path(TARGET_DIR, "updated_output", "hhld_tCostVsInc_NoNegOrZeroInc_freqTable.csv")
write.csv(df_tCostVsInc_NoNegOrZeroInc_freqTable, OUTFILE4, row.names = FALSE)


# ------------------------------------------
# get statistics of tcosts_as_share_of_hhldinc 
# ------------------------------------------

tcosts_as_share_of_hhldinc_mean   <- mean(df_hhldCosts_NoNegOrZeroInc$tcosts_as_share_of_hhldinc)
tcosts_as_share_of_hhldinc_median <- median(df_hhldCosts_NoNegOrZeroInc$tcosts_as_share_of_hhldinc)
tcosts_as_share_of_hhldinc_p90    <- quantile(df_hhldCosts_NoNegOrZeroInc$tcosts_as_share_of_hhldinc, 0.9)
tcosts_as_share_of_hhldinc_max    <- max(df_hhldCosts_NoNegOrZeroInc$tcosts_as_share_of_hhldinc)
# in Pathway 4, I saw that the mean is higher than the p90, there are some really extreme values in the last 10 percentile

df_tCostVsInc_NoNegOrZeroInc_stats <- data.frame(
  tcosts_as_share_of_hhldinc_mean,
  tcosts_as_share_of_hhldinc_median,
  tcosts_as_share_of_hhldinc_p90,
  tcosts_as_share_of_hhldinc_max
)

# export
OUTFILE5 <-file.path(TARGET_DIR, "updated_output", "hhld_tCostVsInc_NoNegOrZeroInc_stats.csv")
write.csv(df_tCostVsInc_NoNegOrZeroInc_stats, OUTFILE5, row.names = FALSE)


