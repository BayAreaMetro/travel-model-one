
# ----------------------------------------------------------------------------------------------------------------
# Analyze_vtoll_distribution.r
#
# This script summarizes value (+ cordon) toll distribution
#
# Inputs:   
# %TARGET_DIR%\updated_output\trips_with_detailed_cost.rdata
# (generated by travel-model-one/utilities/NextGenFwys/metrics/travel-cost-by-income-driving-households.r)
#
# Outputs:  
# (2) %TARGET_DIR%\updated_output\hhld_vtoll_percentile_plot.jpg.
# The x-axis is percentiles; the y-axis is household annual value toll cost. 
# 
# (2) %TARGET_DIR%\updated_output\hhld_vNctoll_percentiles.csv, which contains the variables:
# -- vtollPercentile
# -- vtollValue
# (this file is created in case we want to create the percentile plot in PowerPoint or Excel)
# ----------------------------------------------------------------------------------------------------------------

library(dplyr)
library(knitr) # for the kable function that creates well-formatted tables 

# paths if running this script from command prompt
TARGET_DIR   <- Sys.getenv("TARGET_DIR")  # The location of the input files
TARGET_DIR   <- gsub("\\\\","/",TARGET_DIR) # switch slashes around

# for NGF Round 1, the TARGET_DIR are: 
#TARGET_DIR = "//MODEL2-C/Model2C-Share/Projects/2035_TM152_NGF_NP10_Path4_02"       # new numbering: P1
#TARGET_DIR = "//MODEL3-C/Model3C-Share/Projects/2035_TM152_NGF_NP10_Path3a_02"      # new numbering: 2A
#TARGET_DIR = "//MODEL3-D/Model3D-Share/Projects/2035_TM152_NGF_NP10_Path3b_02"       # new numbering: 2B
#TARGET_DIR = "//MODEL3-A/Model3A-Share/Projects/2035_TM152_NGF_NP10_Path1a_02"      # new numbering: 3A
#TARGET_DIR = "//MODEL3-B/Model3B-Share/Projects/2035_TM152_NGF_NP10_Path1b_02"      # new numbering: P3B
#TARGET_DIR = "//MODEL2-D/Model2D-Share/Projects/2035_TM152_NGF_NP10_Path2a_02_10pc" # new numbering: P4A
#TARGET_DIR = "//MODEL3-D/Model3D-Share/Projects/2035_TM152_NGF_NP10_Path2b_02_10pc" # new numbering: P4B

# create temporary directory for testing purposes
# Define the output directory
output_dir <- file.path(TARGET_DIR, "updated_output_copy")

# Create the directory if it doesn't exist
if (!file.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}


# read inputs
detailedCost_file <- file.path(TARGET_DIR, "updated_output", "trips_with_detailed_cost.rdata")
load(detailedCost_file)

# The dataframe already has a name - it's trips
# Rename dataframe with a df_ prefix to make it easier to remember it is a data frame
df_trips <- trips
rm(trips)

# Note that the input file trips_with_detailed_cost.rdata is a 50% sample
SAMPLESHARE  <- 0.5

#-----------------------------------------------
# Analysis at the trip level
# Keeping this brief for now - as hhld level analysis is more consistent with the metric Affordable 1
# No output tables are generated from the trip level analysis for now! 
#-----------------------------------------------

# note: the values in value_toll came directly from the skims, so they are in the unit of 2000 cents
df_trip_vtoll_freqTable <- df_trips %>%
  filter(is.finite(value_toll)) %>% # note that the value_toll variables has some NAs
  # The bins: The first bin captures the zeroes. The second set of bins range from 0.000001 to 2000 with an increment of 200. The last bin catches everything bigger than 2000.
  mutate(bin = cut(
    value_toll,
    breaks = c(-Inf, seq(0, 0, 1), seq(0.000001, 1000, 100), Inf),
    include.lowest = TRUE,
    right = FALSE
  )) %>%
  count(bin, sort = FALSE)%>%
  mutate(percent_hhld = prop.table(n) * 100) %>%
  mutate(vtoll_lower_bound = as.numeric(sub("\\[([^,]+).*", "\\1", bin)),
         vtoll_upper_bound = as.numeric(sub("[^,]+,([^\\)]+).*", "\\1", bin)))

# note that the input file is a sample (typically at 50% in iter3) so the frequency n should be divided by sampleshare
df_trip_vtoll_freqTable$n=df_trip_vtoll_freqTable$n/SAMPLESHARE

# print the frequency table to the console
print("Frequency Table -- cell values represent the number of trips falling within a certain value_toll bin")
kable(df_trip_vtoll_freqTable, format = "markdown")


# ---
# sidebar: look at the non-finite values in the variable value_toll
df_non_finite_values <- df_trips %>%
  filter(!is.finite(value_toll)) %>%
  select(value_toll)
df_unique_values <- unique(df_non_finite_values$value_toll)
print(df_unique_values)
# all the non-finite values are NAs
# I wonder what the difference is between NA and 0
# ---

# Lots of trips with 0 vtoll. It's not surprising because the trip table includes all modes.
# focus on driving only households
df_DrivingOnly <- df_trips %>%
  filter(hhld_travel == "auto_no_transit")
df_trip_vtoll_freqTable_DrivingHhld <- df_DrivingOnly %>%
  filter(is.finite(value_toll)) %>% # note that the value_toll variables has some NAs
  # The bins: The first bin captures the zeroes. The second set of bins range from 0.000001 to 1000 with an increment of 100. The last bin catches everything bigger than 1000.
  mutate(bin = cut(
    value_toll,
    breaks = c(-Inf, seq(0, 0, 1), seq(0.000001, 1000, 100), Inf),
    include.lowest = TRUE,
    right = FALSE
  )) %>%
  count(bin, sort = FALSE)%>%
  mutate(percent_hhld = prop.table(n) * 100) %>%
  mutate(vtoll_lower_bound = as.numeric(sub("\\[([^,]+).*", "\\1", bin)),
         vtoll_upper_bound = as.numeric(sub("[^,]+,([^\\)]+).*", "\\1", bin)))

# note that the input file is a sample (typically at 50% in iter3) so the frequency n should be divided by sampleshare
df_trip_vtoll_freqTable_DrivingHhld$n = df_trip_vtoll_freqTable_DrivingHhld$n/SAMPLESHARE

# print the frequency table to the console
print("Frequency Table -- cell values represent the number of trips falling within a certain value_toll bin, for driving household only")
kable(df_trip_vtoll_freqTable_DrivingHhld, format = "markdown")

#-----------------------------------------------
# Analysis at the household level
#-----------------------------------------------

df_hhldCosts <- df_trips %>%
  group_by(hh_id) %>%
  summarise(
    hhld_incQ              = first(incQ),
    hhld_incQ_label        = first(incQ_label),
    hhld_income            = first(income),
    hhld_autos             = first(autos),
    home_taz               = first(home_taz),
    hhld_travel            = first(hhld_travel),
    hhld_trips             = first(hhld_trips),
    hhld_auto_seg_trips    = first(hhld_auto_seg_trips),
    hhld_transit_seg_trips = first(hhld_transit_seg_trips),
    total_parking_cost     = sum(totalParkingCost, na.rm = TRUE),
    total_auto_op_cost     = sum(auto_op_cost, na.rm = TRUE),
    total_bridge_toll      = sum(bridge_toll, na.rm = TRUE),
    total_cordon_toll      = sum(cordon_toll, na.rm = TRUE),
    total_value_toll       = sum(value_toll, na.rm = TRUE),
    total_fare             = sum(fare, na.rm = TRUE),
    total_drv_trn_op_cost  = sum(drv_trn_op_cost, na.rm = TRUE),
    total_taxitnc_cost     = sum(taxitnc_cost, na.rm = TRUE)
  )


# ------------------------------------------
# annualize, convert unit to dollars, convert unit from 2000$ to 2023$
# ------------------------------------------

# annualization and inflation factors:
INFLATION_22_23 <- 1.03 # assumption
INFLATION_00_22 <- 327.06 / 180.20 # source: https://github.com/BayAreaMetro/modeling-website/wiki/InflationAssumptions
INFLATION_00_23 <- INFLATION_00_22 * INFLATION_22_23
N_DAYS_PER_YEAR <- 260 #source: https://app.asana.com/0/0/1204323747319792/1205096179253657/f (Please note that for annualization of toll cost/revenue, we should use 260 days (as opposed to 300 days for other annualization calculations like fatalities) since the pathways only toll on weekdays.)

df_hhldCosts <- df_hhldCosts %>%
  mutate(
    annual_parking_cost    = total_parking_cost    * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_auto_op_cost    = total_auto_op_cost    * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_bridge_toll     = total_bridge_toll     * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_cordon_toll     = total_cordon_toll     * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_value_toll      = total_value_toll      * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_fare            = total_fare            * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_drv_trn_op_cost = total_drv_trn_op_cost * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23,
    annual_taxitnc_cost    = total_taxitnc_cost    * N_DAYS_PER_YEAR * 0.01 * INFLATION_00_23
  )


# ------------------------------------------
# add variables related to ownership costs
#   ownership + finance
#   insurance
#   registration/taxes
# ------------------------------------------
# Average Annual Costs of Driving a Car in 2020$
# Same assumptions were used in the NGFS metric script (https://github.com/BayAreaMetro/travel-model-one/blob/master/utilities/NextGenFwys/metrics/ngfs_metrics.py)
# Source: AAA Driving Costs 2020; mid-size sedan
# \Box\NextGen Freeways Study\04 Engagement\02_Stakeholder Engagement\Advisory Group\Meeting 02 - Apr 2022 Existing Conditions\NGFS_Advisory Group Meeting 2_Apr2022.pptx
AUTO_OWNERSHIP_COST_2020D           <- 3400
AUTO_INSURANCE_COST_2020D           <- 1250
AUTO_FINANCE_COST_2020D             <- 680
AUTO_REGISTRATION_TAXES_COST_2020D  <- 730
INFLATION_00_20                     <- 300.08 / 180.20 # source: https://github.com/BayAreaMetro/modeling-website/wiki/InflationAssumptions


df_hhldCosts <- df_hhldCosts %>%
  mutate(
    annual_auto_fixed_costs = hhld_autos *(AUTO_OWNERSHIP_COST_2020D + AUTO_FINANCE_COST_2020D + AUTO_FINANCE_COST_2020D + AUTO_REGISTRATION_TAXES_COST_2020D ) / INFLATION_00_20 * INFLATION_00_23
)

OUTFILE0 <- file.path(TARGET_DIR, "updated_output_copy", "hhldCosts.csv")
write.csv(df_hhldCosts, OUTFILE0, row.names = FALSE)


# -------------------------------------------------------------------------
# a new frequency table that combines value tolls and cordon tolls 
# these two tolls are presented together in NGF Round 1
# -------------------------------------------------------------------------
# add a new variable that sums up annual_value_toll and annual_cordon_toll
df_hhldCosts$annual_valueNcordon_toll =  df_hhldCosts$annual_value_toll + df_hhldCosts$annual_cordon_toll



# plot it
# Calculate percentiles
vNctoll_percentiles <- seq(0, 100, 1)
vNctoll_values     <- quantile(df_hhldCosts$annual_valueNcordon_toll, probs = vNctoll_percentiles/100)

jpeg(file.path(TARGET_DIR, "updated_output_copy","hhld_vNctoll_percentile_plot.jpg"))
plot(vNctoll_percentiles, vNctoll_values, type = "o", xlab = "Percentile", ylab = "annual_valueNcordon_toll", main = "Percentile vs. annual_valueNcordon_toll")
# Save and close the JPEG file
dev.off()

# Create new data frame for export, for plotting in PPT or Excel
df_vNctoll_percentiles <- data.frame(vNctollPercentile = vNctoll_percentiles, vNctollValue = vNctoll_values)

# export
OUTFILE2_vNctoll <- file.path(TARGET_DIR, "updated_output_copy", "hhld_vNctoll_percentiles.csv")
write.csv(df_vNctoll_percentiles , OUTFILE2_vNctoll, row.names = FALSE)

# Define the loop from 1 to 4
for (Q in 1:4) {
  # Filter the data frame for each value of Q
  df_hhldCosts_Q <- df_hhldCosts %>%
    filter(hhld_incQ == Q)
  
  # Compute quantiles
  vNctoll_percentiles <- seq(0, 100, 1)
  vNctoll_values <- quantile(df_hhldCosts_Q$annual_valueNcordon_toll, probs = vNctoll_percentiles / 100)
  
  # Plot
  jpeg(file.path(TARGET_DIR, "updated_output_copy", paste0("hhld_vNctoll_percentile_Q", Q, "_plot.jpg")))
  plot(vNctoll_percentiles, vNctoll_values, type = "o", xlab = "Percentile", ylab = "annual_valueNcordon_toll", main = paste0("Percentile vs. annual_valueNcordon_toll (Q", Q, ")"))
  dev.off()
  
  # Create data frame for export
  df_vNctoll_percentiles_Q <- data.frame(vNctollPercentile = vNctoll_percentiles, vNctollValue = vNctoll_values)
  
  # Export
  OUTFILE2_vNctoll_Q <- file.path(TARGET_DIR, "updated_output_copy", paste0("hhld_vNctoll_percentiles_Q", Q, ".csv"))
  write.csv(df_vNctoll_percentiles_Q, OUTFILE2_vNctoll_Q, row.names = FALSE)
}