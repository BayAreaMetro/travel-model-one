{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage: create a shapefile for comparing two highway networks in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = 'C:\\\\Users\\\\ywang\\\\Documents\\\\ArcGIS\\\\Projects\\\\Network_comparison'\n",
    "folder_1 = '2015_Baseline'\n",
    "folder_2 = '2050_Blueprint'\n",
    "\n",
    "file_1 = os.path.join(working_dir, folder_1, 'freeflow.shp')\n",
    "file_2 = os.path.join(working_dir, folder_2, 'freeflow.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 33798 rows of 2015_Baseline highway link data from C:\\Users\\ywang\\Documents\\ArcGIS\\Projects\\Network_comparison\\2015_Baseline\\freeflow.shp\n",
      "{}\n",
      "Read 34582 rows of 2050_Blueprint highway link data from C:\\Users\\ywang\\Documents\\ArcGIS\\Projects\\Network_comparison\\2050_Blueprint\\freeflow.shp\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# read highway networks shapefile\n",
    "\n",
    "gdf_1 = gpd.read_file(file_1)\n",
    "print('Read {} rows of {} highway link data from {}'.format(gdf_1.shape[0], folder_1, file_1))\n",
    "print(gdf_1.crs)\n",
    "\n",
    "gdf_2 = gpd.read_file(file_2)\n",
    "print('Read {} rows of {} highway link data from {}'.format(gdf_2.shape[0], folder_2, file_2))\n",
    "print(gdf_2.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hwy_link_to_pair(link_df_raw):\n",
    "    \"\"\"\n",
    "    input: .shp, highway network links. Number of rows = number of links in the network\n",
    "    \n",
    "    output: .shp, highway network links collapsed by node pair (number of rows = number of node pairs) with \n",
    "    the following attributes:\n",
    "        AB_pair: node A and node B pair, each pair may contain one link (AB or BA) or two links (AB and BA)\n",
    "        DIS_AB, DIS_BA: distances of the link(s) on each node pair\n",
    "        LN_AB, LN_BA: number of lanes of the link(s) on each node pair\n",
    "        AT_AB, AT_BA: Area Type of the link(s) on each node pair\n",
    "        FT_AB, FT_BA: Facility Type of the link(s) on each node pair\n",
    "        BRT_AB, BRT_BA: BRT type of the link(s) on each node pair\n",
    "        P_AB, P_BA: transportation projects associated with the link(s) on each node pair\n",
    "        DIR: direction of the node pair, 'one-way' or 'two-way'\n",
    "        geometry: lingstring of the node pair\n",
    "    \"\"\"\n",
    "    \n",
    "    link_df = link_df_raw.copy()\n",
    "    link_df.rename(columns = {'DISTANCE': 'DIS',\n",
    "                              'LANES'   : 'LN',\n",
    "                              'PROJ'    : 'P'}, inplace=True)\n",
    "    \n",
    "    # clean up 'None' and 'NaN' in 'P' column\n",
    "    link_df.loc[link_df.P == '']\n",
    "    \n",
    "    # create a variable 'AB_link' to represent A-B link with the original direction,\n",
    "    # and a variable 'AB_pair' to represent the pair of linked nodes without showing the link direction\n",
    "    link_df['AB_link'] = link_df['A'].astype(str) + '-' + link_df['B'].astype(str)\n",
    "    link_df['AB_pair'] = link_df['AB_link']\n",
    "    link_df.loc[link_df.A > link_df.B, 'AB_pair'] = link_df['B'].astype(str) + '-' + link_df['A'].astype(str)\n",
    "    \n",
    "    # only keep needed columns\n",
    "    link_df = link_df[['AB_pair', 'AB_link', 'DIS', 'LN', 'AT', 'FT', 'BRT', 'P', 'geometry']].sort_values(by='AB_pair')\n",
    "    \n",
    "    # calculate each AB_pair has how many links \n",
    "    link_df['link_cnt'] = link_df.groupby('AB_pair')['AB_link'].transform('size')\n",
    "    \n",
    "    # create columns to unstack links of the same node pairs \n",
    "    for i in ['DIS', 'LN', 'AT', 'FT', 'BRT', 'P', 'geometry']:\n",
    "        link_df[i+'_AB_temp'] = None\n",
    "        link_df.loc[link_df.AB_pair == link_df.AB_link, i+'_AB_temp'] = link_df[i]\n",
    "        link_df[i+'_BA_temp'] = None\n",
    "        link_df.loc[link_df.AB_pair != link_df.AB_link, i+'_BA_temp'] = link_df[i]\n",
    "\n",
    "    # fill out values for node pairs\n",
    "    for i in ['DIS', 'LN', 'AT', 'FT', 'BRT', 'P', 'geometry']:\n",
    "        df_AB = link_df.loc[link_df[i+'_AB_temp'].notnull()][['AB_pair', i+'_AB_temp']]\n",
    "        df_AB.columns = ['AB_pair', i + '_AB']\n",
    "        df_BA = link_df.loc[link_df[i+'_BA_temp'].notnull()][['AB_pair', i+'_BA_temp']]\n",
    "        df_BA.columns = ['AB_pair', i + '_BA']\n",
    "\n",
    "        link_df = link_df.merge(df_AB, on='AB_pair', how='left').merge(df_BA, on='AB_pair', how='left')\n",
    "        link_df.drop(columns = [i+'_AB_temp', i+'_BA_temp'], inplace=True)\n",
    "    print('link_df has {} rows'.format(link_df.shape[0]))\n",
    "    \n",
    "    # keep unique node pairs\n",
    "    link_pair = link_df[['AB_pair', 'link_cnt', 'DIS_AB', 'DIS_BA',\n",
    "                         'LN_AB', 'LN_BA', 'AT_AB', 'AT_BA',\n",
    "                         'FT_AB', 'FT_BA', 'BRT_AB', 'BRT_BA', 'P_AB', 'P_BA']].drop_duplicates()\n",
    "    \n",
    "    # label whether each link pair is on a one-way segment or a two-way segment\n",
    "    link_pair['DIR'] = 'one-way'\n",
    "    link_pair.loc[link_pair.link_cnt == 2, 'DIR'] = 'two-way'\n",
    "    print('link_pair has {} rows'.format(link_pair.shape[0]))\n",
    "    \n",
    "    # QA/QC: check the number of one-way links\n",
    "    print('Num of node pairs with DIS value in only one direction: {}'.format(\n",
    "        link_pair.loc[link_pair.DIS_AB.isnull() | link_pair.DIS_BA.isnull()].shape[0]))\n",
    "    print('Num of one-way node pairs: {}'.format(link_pair.loc[link_pair.DIR == 'one-way'].shape[0]))\n",
    "    print('Num of two-way node pairs: {}'.format(link_pair.loc[link_pair.DIR == 'two-way'].shape[0]))\n",
    "    \n",
    "    # obtain geometry from the link input and append to the node-pair dataframe\n",
    "    link_df['geometry'] = link_df['geometry_AB']\n",
    "    link_df.loc[link_df['geometry_AB'].isnull(), 'geometry'] = link_df['geometry_BA']\n",
    "    pair_geo = link_df[['AB_pair', 'geometry']].drop_duplicates()\n",
    "    link_pair_geo = link_pair.merge(pair_geo, on='AB_pair', how='left')\n",
    "    link_pair_geo.drop(columns = ['link_cnt'], inplace=True)\n",
    "    \n",
    "    return link_pair_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_df has 33798 rows\n",
      "link_pair has 19864 rows\n",
      "Num of node pairs with DIS value in only one direction: 5930\n",
      "Num of one-way node pairs: 5930\n",
      "Num of two-way node pairs: 13934\n",
      "network 1 converted to 19864 node pairs\n",
      "link_df has 34582 rows\n",
      "link_pair has 20559 rows\n",
      "Num of node pairs with DIS value in only one direction: 6536\n",
      "Num of one-way node pairs: 6536\n",
      "Num of two-way node pairs: 14023\n",
      "network 2 converted to 20559 node pairs\n"
     ]
    }
   ],
   "source": [
    "# Step1: create node pair file for each network version\n",
    "\n",
    "link_shp_1 = hwy_link_to_pair(gdf_1)\n",
    "print('network 1 converted to {} node pairs'.format(link_shp_1.shape[0]))\n",
    "link_shp_2 = hwy_link_to_pair(gdf_2)\n",
    "print('network 2 converted to {} node pairs'.format(link_shp_2.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after merge: 20640\n",
      "Unique node pairs of the two networks: 20640\n"
     ]
    }
   ],
   "source": [
    "# Step2: merge the node-pair tables of the two networks\n",
    "\n",
    "# first, append version label to column names\n",
    "df1 = link_shp_1[['AB_pair', 'DIS_AB', 'LN_AB', 'AT_AB', 'FT_AB', 'BRT_AB', 'P_AB',\n",
    "                  'DIS_BA', 'LN_BA', 'AT_BA', 'FT_BA', 'BRT_BA', 'P_BA', 'DIR']]\n",
    "df1.columns = [x+'_n1' for x in list(df1)]\n",
    "\n",
    "df2 = link_shp_2[['AB_pair', 'DIS_AB', 'LN_AB', 'AT_AB', 'FT_AB', 'BRT_AB', 'P_AB',\n",
    "                  'DIS_BA', 'LN_BA', 'AT_BA', 'FT_BA', 'BRT_BA', 'P_BA', 'DIR']]\n",
    "df2.columns = [x+'_n2' for x in list(df2)]\n",
    "\n",
    "# outer join\n",
    "df_comp = df1.merge(df2, left_on='AB_pair_n1', right_on='AB_pair_n2', how='outer')\n",
    "\n",
    "# QA/QC: check number of node pairs\n",
    "print('Number of rows after merge: {}'.format(df_comp.shape[0]))\n",
    "print('Unique node pairs of the two networks: {}'.format(df_comp[['AB_pair_n1', 'AB_pair_n2']].drop_duplicates().shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step3: create columns 'diff_xx' to compare each feature: 1 for value change, 0 for no value change \n",
    "\n",
    "for i in ['DIS_AB', 'LN_AB', 'AT_AB', 'FT_AB', 'BRT_AB', 'P_AB',\n",
    "          'DIS_BA', 'LN_BA', 'AT_BA', 'FT_BA', 'BRT_BA', 'P_BA']:\n",
    "    df_comp['diff_'+i] = 0\n",
    "    df_comp.loc[df_comp[i+'_n1'] != df_comp[i+'_n2'], 'diff_'+i] = 1\n",
    "    df_comp.loc[df_comp[i+'_n1'].isnull() & df_comp[i+'_n2'].isnull(), 'diff_'+i] = 0\n",
    "\n",
    "for i in ['DIS', 'LN', 'AT', 'FT', 'BRT', 'P']:\n",
    "    df_comp['diff_'+i] = 0\n",
    "    df_comp.loc[(df_comp['diff_'+i+'_AB'] == 1)|(df_comp['diff_'+i+'_BA'] == 1), 'diff_'+i] = 1\n",
    "    \n",
    "# create 'any_diff' to label is any change exists\n",
    "compare_columns = ['diff_'+x for x in ['DIS', 'LN', 'AT', 'FT', 'BRT', 'P']]\n",
    "df_comp['diff_any'] = df_comp[compare_columns].sum(axis=1)\n",
    "# print(df_comp.diff_any.value_counts())\n",
    "\n",
    "# if a node pair has one attribute change and P_diff==1 (project change), then\n",
    "# there are changes in attributes other than DISTANCE, LANES, AT, FT, BRT\n",
    "df_comp['diff_other'] = 0\n",
    "df_comp.loc[(df_comp.diff_any==1) & (df_comp.diff_P==1), 'diff_other'] = 1\n",
    "\n",
    "# convert diff_any to 1 or 0\n",
    "df_comp.loc[df_comp.diff_any > 0, 'diff_any'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: create columns 'link_chg' to represent if link(s) were added or deleted between the two networks\n",
    "df_comp['link_chg'] = 'No link change'\n",
    "df_comp.loc[df_comp.diff_any==1, 'link_chg'] = 'Other link change'\n",
    "\n",
    "# if DIR_n1 is null or DIR_n1 < DIR_n2, link added\n",
    "df_comp.loc[(df_comp.DIR_n1.isnull() & df_comp.DIR_n2.notnull()) | (\n",
    "             (df_comp.DIR_n1 == 'one-way') & (df_comp.DIR_n2 == 'two-way')), 'link_chg'] = 'Link added'\n",
    "\n",
    "# if DIR_n2 is null or DIR_n1 > DIR_n2, link deleted\n",
    "df_comp.loc[(df_comp.DIR_n1.notnull() & df_comp.DIR_n2.isnull()) | (\n",
    "             (df_comp.DIR_n1 == 'two-way') & (df_comp.DIR_n2 == 'one-way')), 'link_chg'] = 'Link deleted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: consolidate Proj_AB and Proj_BA into one variable - easy for visualization\n",
    "for i in ['_n1', '_n2']:\n",
    "    df_comp['P'+i] = None\n",
    "    df_comp.loc[df_comp['P_AB'+i].isnull() & df_comp['P_BA'+i].notnull(),\n",
    "                'P'+i] = df_comp['P_BA'+i].astype(str)+'(BA)'    \n",
    "    df_comp.loc[df_comp['P_AB'+i].notnull() & df_comp['P_BA'+i].isnull(),\n",
    "                'P'+i] = df_comp['P_AB'+i].astype(str)+'(AB)'\n",
    "    df_comp.loc[df_comp['P_AB'+i].notnull() & df_comp['P_BA'+i].notnull(),\n",
    "                'P'+i] = df_comp['P_AB'+i].astype(str)+'(AB)/' + df_comp['P_BA'+i].astype(str)+'(BA)'\n",
    "    df_comp.loc[df_comp['P_AB'+i].notnull() & df_comp['P_BA'+i].notnull() & (df_comp['P_AB'+i] == df_comp['P_BA'+i]),\n",
    "                'P'+i] = df_comp['P_AB'+i].astype(str)+'(AB/BA)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: join geometry back to the dataframe\n",
    "df_comp_geo = df_comp.merge(link_shp_1[['AB_pair', 'geometry']],\n",
    "                            left_on='AB_pair_n1',\n",
    "                            right_on='AB_pair',\n",
    "                            how='left').merge(link_shp_2[['AB_pair', 'geometry']],\n",
    "                                              left_on='AB_pair_n2',\n",
    "                                              right_on='AB_pair',\n",
    "                                              how='left')\n",
    "df_comp_geo['geometry'] = df_comp_geo['geometry_x']\n",
    "df_comp_geo.loc[df_comp_geo.geometry_x.isnull(), 'geometry'] = df_comp_geo['geometry_y']\n",
    "\n",
    "df_comp_geo.drop(columns = ['AB_pair_x', 'AB_pair_y', 'geometry_x', 'geometry_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export 20640 rows of node-pair comparison data\n"
     ]
    }
   ],
   "source": [
    "# Step 7: define geometry and export\n",
    "df_comp_geo = gpd.GeoDataFrame(df_comp_geo, crs=\"EPSG:26910\", geometry='geometry')\n",
    "print('export {} rows of node-pair comparison data'.format(df_comp_geo.shape[0]))\n",
    "df_comp_geo.to_file(os.path.join(working_dir, 'hwy_link_comp.shp'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
