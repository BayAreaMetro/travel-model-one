{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = 'M:\\\\Application\\\\Model One\\\\RTP2021\\\\Blueprint\\\\VMT per capita or worker'\n",
    "os.chdir(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1454 rows of TAZ1454 shapefile\n",
      "['SUPERD', 'TAZ1454', 'Shape__Are', 'Shape__Len', 'geometry']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUPERD</th>\n",
       "      <th>TAZ1454</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUPERD  TAZ1454\n",
       "0      18      939\n",
       "1      18      974\n",
       "2      18      914\n",
       "3      18      920\n",
       "4      18      921"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "taz = gpd.read_file(r'M:\\Data\\GIS layers\\Travel_Analysis_Zones_(TAZ1454)\\Travel Analysis Zones.shp')\n",
    "print('Read {} rows of TAZ1454 shapefile'.format(taz.shape[0]))\n",
    "print(list(taz))\n",
    "taz = taz[['SUPERD','TAZ1454']]\n",
    "display(taz.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 34 rows of superdistrict ID-name lookup\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUPERD</th>\n",
       "      <th>SD_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Greater Downtown San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>San Francisco Richmond District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>San Francisco Mission District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>San Francisco Sunset District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Daly City and San Bruno</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUPERD                          SD_NAME\n",
       "0       1   Greater Downtown San Francisco\n",
       "1       2  San Francisco Richmond District\n",
       "2       3   San Francisco Mission District\n",
       "3       4    San Francisco Sunset District\n",
       "4       5          Daly City and San Bruno"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1454 rows of TAZ-county lookup\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taz_key</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   taz_key         county\n",
       "0        1  San Francisco\n",
       "1        2  San Francisco\n",
       "2        3  San Francisco\n",
       "3        4  San Francisco\n",
       "4        5  San Francisco"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SD_name = pd.read_csv(r'M:\\Data\\GIS layers\\TM1_taz\\superdistrict_names.csv')\n",
    "print('Read {} rows of superdistrict ID-name lookup'.format(SD_name.shape[0]))\n",
    "display(SD_name.head())\n",
    "\n",
    "taz_county = pd.read_csv(r'C:\\Users\\{}\\Documents\\GitHub\\petrale\\zones\\taz1454\\taz1454_names.csv'.format(os.getenv('USERNAME')),\n",
    "                        usecols = ['taz_key', 'county'])\n",
    "print('Read {} rows of TAZ-county lookup'.format(taz_county.shape[0]))\n",
    "\n",
    "county_dict = {'sfr': 'San Francisco',\n",
    "               'smt': 'San Mateo',\n",
    "               'scl': 'Santa Clara',\n",
    "               'ala': 'Alameda',\n",
    "               'cnc': 'Contra Costa',\n",
    "               'sol': 'Solano',\n",
    "               'nap': 'Napa',\n",
    "               'son': 'Sonoma',\n",
    "               'mar': 'Marin'}\n",
    "taz_county['county'] = taz_county['county'].map(county_dict)\n",
    "display(taz_county.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz = taz.merge(taz_county,\n",
    "                left_on='TAZ1454',\n",
    "                right_on='taz_key',\n",
    "                how='inner').merge(SD_name,\n",
    "                                   on='SUPERD',\n",
    "                                   how='left')\n",
    "taz.drop(columns=['taz_key'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz.to_csv(os.path.join(run_dir, 'Tableau', 'taz_index.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### home vmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vmt_percapita_cat(x):\n",
    "    if x > 20:\n",
    "        return 'More than 20'\n",
    "    elif x > 15:\n",
    "        return '15 to 20'\n",
    "    elif x > 10:\n",
    "        return '10 to 15'\n",
    "    elif x > 5:\n",
    "        return '5 to 10'\n",
    "    else:\n",
    "        return 'Less than 5'\n",
    "\n",
    "def vmt_perworker_cat(x):\n",
    "    if x > 30:\n",
    "        return 'More than 30'\n",
    "    elif x > 25:\n",
    "        return '25 to 30'\n",
    "    elif x > 20:\n",
    "        return '20 to 25'\n",
    "    elif x > 15:\n",
    "        return '15 to 20'\n",
    "    else:\n",
    "        return 'Less than 15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home_2025_TM152_FBP_Plus_22.csv has 1445 rows of TAZ summary data\n",
      "scen: PBA50_Plus, year: 2025, run: 22\n",
      "Home_2030_06_694.csv has 1441 rows of TAZ summary data\n",
      "scen: PBA40, year: 2030, run: 06_694\n",
      "Home_2030_TM152_FBP_Plus_23.csv has 1447 rows of TAZ summary data\n",
      "scen: PBA50_Plus, year: 2030, run: 23\n",
      "Home_2035_TM152_EIR_Alt1_06.csv has 1447 rows of TAZ summary data\n",
      "scen: PBA50_Alt1, year: 2035, run: 06\n",
      "Home_2035_TM152_EIR_Alt2_04.csv has 1449 rows of TAZ summary data\n",
      "scen: PBA50_Alt2, year: 2035, run: 04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home_2035_TM152_FBP_NoProject_24.csv has 1446 rows of TAZ summary data\n",
      "scen: PBA50_NP, year: 2035, run: 24\n",
      "Home_2035_TM152_FBP_Plus_24.csv has 1448 rows of TAZ summary data\n",
      "scen: PBA50_Plus, year: 2035, run: 24\n",
      "Home_2040_06_694_Amd1.csv has 1441 rows of TAZ summary data\n",
      "scen: PBA40, year: 2040, run: 06_694_Amd1\n",
      "Home_2040_TM152_FBP_Plus_24.csv has 1448 rows of TAZ summary data\n",
      "scen: PBA50_Plus, year: 2040, run: 24\n",
      "Home_2050_TM152_EIR_Alt1_06.csv has 1449 rows of TAZ summary data\n",
      "scen: PBA50_Alt1, year: 2050, run: 06\n",
      "Home_2050_TM152_EIR_Alt2_05.csv has 1448 rows of TAZ summary data\n",
      "scen: PBA50_Alt2, year: 2050, run: 05\n",
      "Home_2050_TM152_FBP_NoProject_24.csv has 1444 rows of TAZ summary data\n",
      "scen: PBA50_NP, year: 2050, run: 24\n",
      "Home_2050_TM152_FBP_PlusCrossing_24.csv has 1449 rows of TAZ summary data\n",
      "scen: PBA50_Plus, year: 2050, run: 24\n",
      "Work_2025_TM152_FBP_Plus_22.csv has 1453 rows of TAZ summary data\n",
      "scen: PBA50_Plus, year: 2025, run: 22\n",
      "Work_2030_06_694.csv has 1455 rows of TAZ summary data"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "C:\\Users\\ywang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "scen: PBA40, year: 2030, run: 06_694\n",
      "Work_2030_TM152_FBP_Plus_23.csv has 1453 rows of TAZ summary data\n",
      "scen: PBA50_Plus, year: 2030, run: 23\n",
      "Work_2035_TM152_EIR_Alt1_06.csv has 1452 rows of TAZ summary data\n",
      "scen: PBA50_Alt1, year: 2035, run: 06\n",
      "Work_2035_TM152_EIR_Alt2_04.csv has 1453 rows of TAZ summary data\n",
      "scen: PBA50_Alt2, year: 2035, run: 04\n",
      "Work_2035_TM152_FBP_NoProject_24.csv has 1452 rows of TAZ summary data\n",
      "scen: PBA50_NP, year: 2035, run: 24\n",
      "Work_2035_TM152_FBP_Plus_24.csv has 1453 rows of TAZ summary data\n",
      "scen: PBA50_Plus, year: 2035, run: 24\n",
      "Work_2040_06_694_Amd1.csv has 1455 rows of TAZ summary data\n",
      "scen: PBA40, year: 2040, run: 06_694_Amd1\n",
      "Work_2040_TM152_FBP_Plus_24.csv has 1453 rows of TAZ summary data\n",
      "scen: PBA50_Plus, year: 2040, run: 24\n",
      "Work_2050_TM152_EIR_Alt1_06.csv has 1453 rows of TAZ summary data\n",
      "scen: PBA50_Alt1, year: 2050, run: 06\n",
      "Work_2050_TM152_EIR_Alt2_05.csv has 1451 rows of TAZ summary data\n",
      "scen: PBA50_Alt2, year: 2050, run: 05\n",
      "Work_2050_TM152_FBP_NoProject_24.csv has 1450 rows of TAZ summary data\n",
      "scen: PBA50_NP, year: 2050, run: 24\n",
      "Work_2050_TM152_FBP_PlusCrossing_24.csv has 1453 rows of TAZ summary data\n",
      "scen: PBA50_Plus, year: 2050, run: 24\n"
     ]
    }
   ],
   "source": [
    "vmt_by_TAZ = pd.DataFrame(columns=['TAZ1454',\n",
    "                                   'total_vmt_resident', 'total_pop_resident',\n",
    "                                   'vmtpercapita', 'vmtpercapitaCat',\n",
    "                                   'total_vmt_worker', 'total_pop_worker',\n",
    "                                   'vmtperworker', 'vmtperworkerCat', 'type', 'scen', 'year', 'run'])\n",
    "\n",
    "vmt_by_SD = pd.DataFrame(columns=['SUPERD', 'SD_NAME',\n",
    "                                  'total_vmt_resident', 'total_pop_resident',\n",
    "                                  'vmtpercapita', 'vmtpercapitaCat',\n",
    "                                  'total_vmt_worker', 'total_pop_worker',\n",
    "                                  'vmtperworker', 'vmtperworkerCat', 'type', 'scen', 'year', 'run'])\n",
    "\n",
    "vmt_by_COUNTY = pd.DataFrame(columns=['county',\n",
    "                                      'total_vmt_resident', 'total_pop_resident',\n",
    "                                      'vmtpercapita', 'vmtpercapitaCat',\n",
    "                                      'total_vmt_worker', 'total_pop_worker',\n",
    "                                      'vmtperworker', 'vmtperworkerCat', 'type', 'scen', 'year', 'run'])\n",
    "\n",
    "\n",
    "for file in list(glob.glob('*.csv')):\n",
    "#     print(file)\n",
    "    \n",
    "    if 'Home' in file:\n",
    "        df = pd.read_csv(file, usecols = ['taz', 'total_vmt', 'total_pop', 'vmtpercapita'])\n",
    "        df.rename(columns = {'taz': 'TAZ1454',\n",
    "                             'total_vmt': 'total_vmt_resident',\n",
    "                             'total_pop': 'total_pop_resident'}, inplace=True)\n",
    "    elif 'Work' in file:\n",
    "        df = pd.read_csv(file, usecols = ['WorkLocation', 'total_vmt', 'total_pop', 'vmtperworker'])\n",
    "        df.rename(columns = {'WorkLocation': 'TAZ1454',\n",
    "                             'total_vmt': 'total_vmt_worker',\n",
    "                             'total_pop': 'total_pop_worker'}, inplace=True)\n",
    "        \n",
    "    print('{} has {} rows of TAZ summary data'.format(file, df.shape[0]))\n",
    "    \n",
    "    df = df.merge(taz, on='TAZ1454', how='right')\n",
    "#     display(df.head())\n",
    "\n",
    "    # summarize by SD and County\n",
    "    if 'Home' in file:\n",
    "        for i in ['total_vmt_resident', 'total_pop_resident']:\n",
    "            df[i] = df[i].fillna(0)\n",
    "\n",
    "        df_SD = df.groupby(['SUPERD', 'SD_NAME'])['total_vmt_resident', 'total_pop_resident'].sum().reset_index()\n",
    "        df_SD['vmtpercapita'] = df_SD['total_vmt_resident']/df_SD['total_pop_resident']\n",
    "        \n",
    "        df_county = df.groupby('county')['total_vmt_resident', 'total_pop_resident'].sum().reset_index()\n",
    "        df_county['vmtpercapita'] = df_county['total_vmt_resident']/df_county['total_pop_resident']\n",
    "        \n",
    "    if 'Work' in file:\n",
    "        for i in ['total_vmt_worker', 'total_pop_worker']:\n",
    "            df[i] = df[i].fillna(0)\n",
    "        \n",
    "        df_SD = df.groupby(['SUPERD', 'SD_NAME'])['total_vmt_worker', 'total_pop_worker'].sum().reset_index()\n",
    "        df_SD['vmtperworker'] = df_SD['total_vmt_worker']/df_SD['total_pop_worker']\n",
    "        \n",
    "        df_county = df.groupby('county')['total_vmt_worker', 'total_pop_worker'].sum().reset_index()\n",
    "        df_county['vmtperworker'] = df_county['total_vmt_worker']/df_county['total_pop_worker']\n",
    "        \n",
    "       \n",
    "    # add fields to represent output scenario, year, and run_id\n",
    "    run_year = file.split('.')[0].split('_')[1]\n",
    "\n",
    "    if 'TM152' in file:\n",
    "        if file.split('.')[0].split('_')[4] == 'NoProject':\n",
    "            scen = 'PBA50_NP'\n",
    "            run_id = file.split('.')[0].split('_')[5]\n",
    "        elif file.split('.')[0].split('_')[4] == 'Plus':\n",
    "            scen = 'PBA50_Plus'\n",
    "            run_id = file.split('.')[0].split('_')[5]\n",
    "        elif file.split('.')[0].split('_')[4] == 'PlusCrossing':\n",
    "            scen = 'PBA50_Plus'\n",
    "            run_id = file.split('.')[0].split('_')[5]\n",
    "        else:\n",
    "            scen = 'PBA50_' + file.split('.')[0].split('_')[4]\n",
    "            run_id = file.split('.')[0].split('_')[5]\n",
    "    elif '06_694' in file:\n",
    "        scen = 'PBA40'\n",
    "        run_id = file.split('.')[0][10:]\n",
    "\n",
    "    print('scen: {}, year: {}, run: {}'.format(scen, run_year, run_id))\n",
    "    \n",
    "    if 'Home' in file:\n",
    "        df['type'] = 'resident'\n",
    "        df_SD['type'] = 'resident'\n",
    "        df_county['type'] = 'resident'\n",
    "    elif 'Work' in file:\n",
    "        df['type'] = 'worker'\n",
    "        df_SD['type'] = 'worker'\n",
    "        df_county['type'] = 'worker'\n",
    "    \n",
    "    df['scen'] = scen\n",
    "    df_SD['scen'] = scen\n",
    "    df_county['scen'] = scen\n",
    "    \n",
    "    df['year'] = run_year\n",
    "    df_SD['year'] = run_year\n",
    "    df_county['year'] = run_year\n",
    "    \n",
    "    df['run'] = run_id\n",
    "    df_SD['run'] = run_id\n",
    "    df_county['run'] = run_id\n",
    "\n",
    "    if 'Home' in file:\n",
    "        df['vmtpercapitaCat'] = df['vmtpercapita'].apply(lambda x: vmt_percapita_cat(x))\n",
    "        df_SD['vmtpercapitaCat'] = df_SD['vmtpercapita'].apply(lambda x: vmt_percapita_cat(x))\n",
    "        df_county['vmtpercapitaCat'] = df_county['vmtpercapita'].apply(lambda x: vmt_percapita_cat(x))\n",
    "    elif 'Work' in file:    \n",
    "        df['vmtperworkerCat'] = df['vmtperworker'].apply(lambda x: vmt_perworker_cat(x))\n",
    "        df_SD['vmtperworkerCat'] = df_SD['vmtperworker'].apply(lambda x: vmt_perworker_cat(x))\n",
    "        df_county['vmtperworkerCat'] = df_county['vmtperworker'].apply(lambda x: vmt_perworker_cat(x))\n",
    "    \n",
    "#     display(df)\n",
    "#     display(df_SD)\n",
    "#     display(df_county)\n",
    "\n",
    "    vmt_by_TAZ = pd.concat([vmt_by_TAZ, df])\n",
    "    vmt_by_SD = pd.concat([vmt_by_SD, df_SD])\n",
    "    vmt_by_COUNTY = pd.concat([vmt_by_COUNTY, df_county])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmt_by_TAZ.to_csv(os.path.join(run_dir, 'Tableau', 'vmt_by_TAZ.csv'), index=False)\n",
    "vmt_by_SD.to_csv(os.path.join(run_dir, 'Tableau', 'vmt_by_SD.csv'), index=False)\n",
    "vmt_by_COUNTY.to_csv(os.path.join(run_dir, 'Tableau', 'vmt_by_COUNTY.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
