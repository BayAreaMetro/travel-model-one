{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This script is for estimating an updated WFH model for TM1.6.1. The [initial WFH model created for TM1.6.0](https://github.com/BayAreaMetro/travel-model-one/pull/63) was estimated using ACS 2021 data (and later updated to use ACS 2022 data) based on household income, home county, and industry. However, ACS and ACS PUMS data on WFH has the limitation that for workers who report WFH as their primary journey-to-work mode for the reference week, no distinct workplace (from home) is reported.\n",
    "\n",
    "MTC staff looked at data from the [2023 Bay Area Travel Study (BATS)](https://mtc.ca.gov/tools-resources/survey-program) where workplace location was reported for all respondents who had a workplace, even if they worked from home on a survey day. We [found that the distances between work and home tended to be longer for people who worked from home](https://10ay.online.tableau.com/t/metropolitantransportationcommission/views/BATS-2023-SurveyDataViz--WeightedDataset_09112024_17261683633090/Dist-to-WorkTable), which is intuitve because a longer commute would incentive workers to WFH. However, the ACS-based WFH model implemented resulted in the reverse pattern.\n",
    "\n",
    "Therefore, the goal here is to estimate a simple model using BATS 2023 data and a similar set of independent variables (to minimize implementation effort due to limited time available), but with the addition of a distance-to-work term included.\n",
    "\n",
    "Asana task (internal): [Estimate WFH binomial logit model using BATS2023](https://app.asana.com/0/15119358130897/1208621825395379/f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare BATS 2023 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default is C:/Users/username/Box\n",
    "BOX_ROOT_DIR = pathlib.Path(\"C:/Users\") / os.environ['USERNAME'] / \"Box\"\n",
    "if (os.environ['USERNAME'] == 'lzorn'):\n",
    "    BOX_ROOT_DIR = pathlib.Path(\"E:/Box\")\n",
    "\n",
    "BATS_DATA_DIR = BOX_ROOT_DIR / \"Modeling and Surveys\" / \"Surveys\" / \"Travel Diary Survey\" / \"Biennial Travel Diary Survey\" / \\\n",
    "    \"MTC_RSG_Partner Repository\" / \"5.Deliverables\" / \"Task 10 - Final Weighted and Expanded Data Files\" / \"WeightedDataset_09112024\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read Households data for household income, home location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 8,258 rows from \"E:\\Box\\Modeling and Surveys\\Surveys\\Travel Diary Survey\\Biennial Travel Diary Survey\\MTC_RSG_Partner Repository\\5.Deliverables\\Task 10 - Final Weighted and Expanded Data Files\\WeightedDataset_09112024\\hh.csv\n",
      "\n",
      "All records have home_in_region==1:\n",
      "home_in_region\n",
      "1    8258\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Income variable tabulation:\n",
      "income_detailed  income_imputed   \n",
      "7                $100,000-$199,999    1370\n",
      "10               $200,000 or more     1235\n",
      "8                $100,000-$199,999     935\n",
      "6                $75,000-$99,999       852\n",
      "5                $50,000-$74,999       761\n",
      "9                $200,000 or more      622\n",
      "999              $100,000-$199,999     547\n",
      "1                Under $25,000         428\n",
      "4                $25,000-$49,999       417\n",
      "2                Under $25,000         305\n",
      "3                $25,000-$49,999       303\n",
      "999              $200,000 or more      261\n",
      "                 Under $25,000         122\n",
      "                 $25,000-$49,999        45\n",
      "                 $50,000-$74,999        29\n",
      "                 $75,000-$99,999        26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# read households\n",
    "bats_hhlds = pd.read_csv(BATS_DATA_DIR / \"hh.csv\")\n",
    "print(f\"Read {len(bats_hhlds):,} rows from \\\"{BATS_DATA_DIR / 'hh.csv'}\")\n",
    "\n",
    "# print(\"\\nbats_hhlds.dtypes:\")\n",
    "# print(bats_hhlds.dtypes)\n",
    "\n",
    "# select relevant variables\n",
    "bats_hhlds = bats_hhlds[[\n",
    "    'hh_id',\n",
    "    'home_lon','home_lat','home_in_region','home_county',\n",
    "    'income_detailed','income_followup','income_broad','income_imputed']]\n",
    "\n",
    "# filter to home_in_region? Not necesary -- these are all 1\n",
    "print(\"\\nAll records have home_in_region==1:\")\n",
    "print(bats_hhlds['home_in_region'].value_counts(dropna=False))\n",
    "\n",
    "# use income_imputed?\n",
    "print(\"\\nIncome variable tabulation:\")\n",
    "print(bats_hhlds[['income_detailed','income_imputed']].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Read Person data for employment status, work location and industry\n",
    "\n",
    "Filter to employed persons who have a recorded work location in the region.\n",
    "Merge with households information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 15,985 rows from \"E:\\Box\\Modeling and Surveys\\Surveys\\Travel Diary Survey\\Biennial Travel Diary Survey\\MTC_RSG_Partner Repository\\5.Deliverables\\Task 10 - Final Weighted and Expanded Data Files\\WeightedDataset_09112024\\person.csv\"\n",
      "\n",
      "Filtering to: employment == 1 Employed full-time (paid) or 2 Employed part-time (paid)\n",
      " => 8,374 rows\n",
      "\n",
      "Work in region vs has_work_location tabulation:\n",
      "work_in_region  has_work_location\n",
      "1               True                 5982\n",
      "995             False                2328\n",
      "0               True                   64\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtering to: work_in_region==1 and has_work_location==True\n",
      " => 5,982 rows\n"
     ]
    }
   ],
   "source": [
    "# read persons\n",
    "bats_persons = pd.read_csv(BATS_DATA_DIR / \"person.csv\")\n",
    "print(f\"Read {len(bats_persons):,} rows from \\\"{BATS_DATA_DIR / 'person.csv'}\\\"\")\n",
    "\n",
    "# print(\"\\nbats_persons.dtypes:\")\n",
    "# print(bats_persons.dtypes)\n",
    "\n",
    "# select relevant variables\n",
    "bats_persons = bats_persons[[\n",
    "    'hh_id','person_id',\n",
    "    'employment','work_lat','work_lon','work_in_region','work_county','industry',\n",
    "    'can_telework']]\n",
    "\n",
    "print(\"\\nFiltering to: employment == 1 Employed full-time (paid) or 2 Employed part-time (paid)\")\n",
    "bats_persons = bats_persons.loc[bats_persons.employment.isin([1,2])]\n",
    "print(f\" => {len(bats_persons):,} rows\")\n",
    "\n",
    "# set variable for has_work_location\n",
    "bats_persons['has_work_location'] = False\n",
    "bats_persons.loc[pd.notna(bats_persons.work_lat) & pd.notna(bats_persons.work_lon), \"has_work_location\"] = True\n",
    "\n",
    "print(\"\\nWork in region vs has_work_location tabulation:\")\n",
    "print(bats_persons[[\"work_in_region\",\"has_work_location\"]].value_counts(dropna=False))\n",
    "\n",
    "# It looks like work_in_region==995 => has_work_location==False\n",
    "# Drop work_in_region==0 and has_work_location==False\n",
    "print(\"\\nFiltering to: work_in_region==1 and has_work_location==True\")\n",
    "bats_persons = bats_persons.loc[(bats_persons.work_in_region == 1)&\n",
    "                                (bats_persons.has_work_location==True)]\n",
    "print(f\" => {len(bats_persons):,} rows\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Merge persons with households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with households\n",
    "bats_persons = pd.merge(\n",
    "    left=bats_persons,\n",
    "    right=bats_hhlds,\n",
    "    on=['hh_id'],\n",
    "    how='left',\n",
    "    validate='many_to_one',\n",
    "    indicator=True\n",
    ")\n",
    "# verify all person records have household information\n",
    "assert all(bats_persons['_merge'] == 'both'), \"Not all values in _merge are 'both'\"\n",
    "bats_persons.drop(columns=['_merge'],inplace=True)\n",
    "# bats_persons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Read Day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 89,112 rows from \"E:\\Box\\Modeling and Surveys\\Surveys\\Travel Diary Survey\\Biennial Travel Diary Survey\\MTC_RSG_Partner Repository\\5.Deliverables\\Task 10 - Final Weighted and Expanded Data Files\\WeightedDataset_09112024\\day.csv\"\n",
      "\n",
      "bats_day.dtypes:\n",
      "hh_id                          int64\n",
      "num_trips                      int64\n",
      "person_id                      int64\n",
      "person_num                     int64\n",
      "hh_is_complete                 int64\n",
      "hh_is_complete_a               int64\n",
      "hh_is_complete_b               int64\n",
      "surveyable                     int64\n",
      "is_participant                 int64\n",
      "is_complete                    int64\n",
      "is_complete_a                  int64\n",
      "is_complete_b                  int64\n",
      "day_id                         int64\n",
      "day_num                        int64\n",
      "travel_date                   object\n",
      "travel_dow                     int64\n",
      "num_complete_trip_surveys      int64\n",
      "hh_day_complete                int64\n",
      "hh_day_complete_a              int64\n",
      "hh_day_complete_b              int64\n",
      "num_flagged_trips              int64\n",
      "day_pct_trips_flagged        float64\n",
      "proxy_complete                 int64\n",
      "begin_day                      int64\n",
      "end_day                        int64\n",
      "telecommute_time             float64\n",
      "school_daily                   int64\n",
      "attend_school_1                int64\n",
      "attend_school_2                int64\n",
      "attend_school_3                int64\n",
      "attend_school_998              int64\n",
      "attend_school_999              int64\n",
      "attend_school_no_1             int64\n",
      "attend_school_no_2             int64\n",
      "attend_school_no_3             int64\n",
      "attend_school_no_4             int64\n",
      "attend_school_no_5             int64\n",
      "attend_school_no_997           int64\n",
      "attend_school_no_998           int64\n",
      "attend_school_no_999           int64\n",
      "delivery_2                     int64\n",
      "delivery_3                     int64\n",
      "delivery_4                     int64\n",
      "delivery_5                     int64\n",
      "delivery_6                     int64\n",
      "delivery_7                     int64\n",
      "delivery_8                     int64\n",
      "delivery_9                     int64\n",
      "delivery_996                   int64\n",
      "made_travel                    int64\n",
      "no_travel_1                    int64\n",
      "no_travel_2                    int64\n",
      "no_travel_3                    int64\n",
      "no_travel_4                    int64\n",
      "no_travel_5                    int64\n",
      "no_travel_6                    int64\n",
      "no_travel_7                    int64\n",
      "no_travel_8                    int64\n",
      "no_travel_9                    int64\n",
      "no_travel_11                   int64\n",
      "no_travel_12                   int64\n",
      "no_travel_99                   int64\n",
      "num_reasons_no_travel          int64\n",
      "day_weight                   float64\n",
      "day_weight_rmove_only        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# read day data for day of week and telecommute time spent\n",
    "bats_day = pd.read_csv(BATS_DATA_DIR / \"day.csv\")\n",
    "print(f\"Read {len(bats_day):,} rows from \\\"{BATS_DATA_DIR / 'day.csv'}\\\"\")\n",
    "\n",
    "print(\"\\nbats_day.dtypes:\")\n",
    "print(bats_day.dtypes)\n",
    "\n",
    "# select relevant variables\n",
    "bats_day = bats_day[[\n",
    "    'hh_id','person_id','day_id',\n",
    "    'travel_date','travel_dow',\n",
    "    'telecommute_time']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NetworkWrangler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
