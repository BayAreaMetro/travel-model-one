{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "#pd.options.display.mpl_style = 'default'\n",
    "\n",
    "#drop=os.environ['DROPBOX_LOC']\n",
    "#dropbox=os.environ['DROPBOX_LOC']\n",
    "\n",
    "#netspass=os.environ['NETSDB_PASS']\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm, matplotlib.font_manager as fm\n",
    "sns.set(style=\"darkgrid\")\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nets = pd.read_csv(os.path.join(drop,'Data/nets2015_long.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from shapely.geometry import Point\n",
    "#from fiona.crs import from_epsg\n",
    "#import geopandas as gpd\n",
    "#from pyproj import Proj\n",
    "#from geopandas.tools import sjoin\n",
    "#from shapely.geometry import Point\n",
    "#from fiona.crs import from_epsg\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import shapely\n",
    "#from platform import python_version\n",
    "\n",
    "#print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "def comma_format(x, p):\n",
    "    return '$'+format(x, \"6,.0f\").replace(\",\", \".\")\n",
    "def percent_format(x, p):\n",
    "    return format(x, \"6,.02f\").replace(\",\", \".\")\n",
    "percent_format = lambda x,pos: '{:,.0f}%'.format(x)\n",
    "comma_format = lambda x,pos: '{:,.0f}'.format(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current size\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print(\"Current size:%s\" %fig_size)\n",
    " \n",
    "# Set figure width to 12 and height to 9\n",
    "fig_size[0] = 11\n",
    "fig_size[1] = 8.5\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "print(\"Current size:%s\" %fig_size)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct=lambda x: x/x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easylabeler(breaks,currency=True,prefix='AGE'):\n",
    "    \"\"\"\n",
    "    turn list of breaks into list of strings for binning / cutting.\n",
    "    Parameters\n",
    "    ----------\n",
    "    breaks : list-like\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : list of named strings\n",
    "    \"\"\"\n",
    "    \n",
    "    if currency:\n",
    "        ptrn_main=\"${fr:,.0f} - ${to:,.0f}\"\n",
    "        ptrn_first='Less than ${dt:,.0f}'\n",
    "        ptrn_last='Greater than ${dt:,.0f}'\n",
    "    else:\n",
    "        ptrn_main=\"{fr:,.0f} - {to:,.0f}\"\n",
    "        ptrn_first='Less than {dt:,.0f}'\n",
    "        ptrn_last='Greater than {dt:,.0f}'\n",
    "    \n",
    "    difflabels=[]\n",
    "    for f in range(len(breaks)-1):\n",
    "        \n",
    "        difflabels.append(ptrn_main.format(fr=breaks[f],to=breaks[f+1]-1))\n",
    "    ## fix first, last boundary entries\n",
    "    difflabels[0]=ptrn_first.format(dt=breaks[1])\n",
    "    difflabels[-1]=ptrn_last.format(dt=breaks[-2])\n",
    "    return difflabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load / define a few mapping files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get SOC, NAICS mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH='/Users/aolsen/Box/Horizon and Plan Bay Area 2050/Blueprint/Final Blueprint Modeling/Protesting Polar Bears/NETS analysis/inputs'\n",
    "OUTPUT_PATH='/Users/aolsen/Box/Horizon and Plan Bay Area 2050/Blueprint/Final Blueprint Modeling/Protesting Polar Bears/NETS analysis'\n",
    "NETS_PATH='/Users/aolsen/Box/DataViz Projects/Data Analysis and Visualization/National Establishment Time Series'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc = pd.read_excel(os.path.join(INPUT_PATH,'soc_structure_2010.xls'),skiprows=11,\n",
    "                   names=[u'Major Group', u'Minor Group', u'Broad Group', u'Detailed Occupation', u'Description'])\n",
    "\n",
    "soc['maj']=soc['Major Group'].fillna('').str.split('-').apply(lambda x: x[0])\n",
    "\n",
    "def classifier(df):\n",
    "    \"\"\"\n",
    "    we need to classify each row with the appropriate hierarchy level.\n",
    "    for each row, we want to get the rightmost value available--\n",
    "    that represents the finest grained detail class\n",
    "    \"\"\"\n",
    "    \n",
    "    x = df.ix[:4].tolist()\n",
    "    try:\n",
    "        out = next(s for s in x if not s is np.NaN)\n",
    "    except:\n",
    "        out = None\n",
    "    return  out\n",
    "\n",
    "def classlevel(s):\n",
    "    \n",
    "    try:\n",
    "        if s[3:]=='0000':\n",
    "            return 'major'\n",
    "        elif np.float64(s[3:]) % 100==0:\n",
    "            return 'minor'\n",
    "        elif np.float64(s[3:]) % 10==0:\n",
    "            return 'broad'\n",
    "        else:\n",
    "            return 'detail'\n",
    "    except:\n",
    "        return 'none'\n",
    "soc['class']=soc.ix[:,:4].apply(classifier,axis=1)\n",
    "soc['hierarchy']=soc['class'].fillna('-1').map(classlevel)\n",
    "\n",
    "soc[['class','hierarchy','Description']].iloc[1200:1202]\n",
    "\n",
    "soc[['class','hierarchy','Description']].groupby('hierarchy').size()\n",
    "soc['Description']=soc.Description.fillna('0').str.lower()\n",
    "#soc.index=SOC['SOCP_2']\n",
    "\n",
    "soc['SOCP_2']=soc['class'].apply(lambda x: str(x)[:2])\n",
    "majorclass = soc.ix[soc['Major Group'].notnull(),['SOCP_2','Description']].copy()\n",
    "majorclass.index=majorclass.SOCP_2\n",
    "majorclass=majorclass.Description.to_dict()\n",
    "\n",
    "soc=soc[soc['class'].notnull()]\n",
    "soc['class']=soc['class'].str.replace('-','')\n",
    "#soc[soc.hierarchy=='major'].to_csv(os.path.join(drop,'Documents/Data/_BLS/SOC/soc_structure_2010_major.csv'))\n",
    "\n",
    "soc_map=soc[soc.hierarchy=='detail'].set_index('Detailed Occupation').Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get abag-naics mapping\n",
    "names=['NAICS','ABAGSector','mtc11','mtc6','EDDSector','acsnames','acscensus']\n",
    "naics_mappings = pd.read_excel(os.path.join(INPUT_PATH, 'NAICS_to_ABAG_SECTORS.xlsx'),sheet_name='both')\n",
    "naics_mappings.columns=names\n",
    "naics_mappings['NAICS']=naics_mappings['NAICS'].astype(str)\n",
    "\n",
    "#naics_abag = pd.read_csv(os.path.join(drop, r'Documents\\Data\\BayArea\\Projections 2013\\NAICS_to_ABAG_SECTORS.csv'),sep='\\t',dtype=object)\n",
    "\n",
    "naics_abag = naics_mappings.set_index('NAICS').mtc11.to_dict()\n",
    "naics_mtc = naics_mappings.set_index('NAICS').mtc6.to_dict()\n",
    "naics_abag_11 = naics_mappings.set_index('NAICS')['mtc11'].to_dict()\n",
    "naics_mappings.mtc11=naics_mappings.mtc11.str.strip()\n",
    "naics_mappings.mtc6=naics_mappings.mtc6.str.strip()\n",
    "naics_mappings.groupby(['acsnames','mtc11']).size().reset_index()\n",
    "naics_mappings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taz = gpd.read_file(os.path.join(drop,'Documents/Data/GIS/zones1454.shp'),crs=from_epsg(3740)).to_crs(from_epsg(3740))\n",
    "# #taz['county']=taz.county_mtc.map(countymap)\n",
    "# taz=taz[taz.geometry.notnull()]\n",
    "\n",
    "# taz['geometry']=taz.buffer(.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## read naics-3 values from file\n",
    "# naicsmap3 =  pd.read_csv(os.path.join(drop,'Documents/Data/Classification/naics_3.csv'),sep='\\t',\n",
    "#   dtype={'Naics_3': object, 'description': object}).set_index('Naics_3').description.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## naics-2 dict\n",
    "naicsmap = {'11':'Agriculture, Forestry, Fishing and Hunting',\n",
    "    '21': 'Mining, Quarrying, and Oil and Gas Extraction',\n",
    " '22': 'Utilities',\n",
    " '23': 'Construction',\n",
    " '31': 'Manufacturing',\n",
    " '32': 'Manufacturing',\n",
    " '33': 'Manufacturing',\n",
    " '42': 'Wholesale Trade',\n",
    " '44': 'Retail Trade',\n",
    " '45': 'Retail Trade',\n",
    " '48': 'Transportation and Warehousing',\n",
    " '49': 'Transportation and Warehousing',\n",
    " '51': 'Information',\n",
    " '52': 'Finance and Insurance',\n",
    " '53': 'Real Estate and Rental and Leasing',\n",
    " '54': 'Professional, Scientific, and Technical Services',\n",
    " '55': 'Management of Companies and Enterprises',\n",
    " '56': 'Administrative and Support and Waste Management and Remediation Services',\n",
    " '61': 'Educational Services',\n",
    " '62': 'Health Care and Social Assistance',\n",
    " '71': 'Arts, Entertainment, and Recreation',\n",
    " '72': 'Accommodation and Food Services',\n",
    " '81': 'Other Services except Public Administration',\n",
    " '92': 'Public Administration',\n",
    " '99': 'Unclassified Establishments'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## define dicts relating the field name in the data to the year it represents (e.g. NAICS01: 2001)\n",
    "# ## we use later to extract the year\n",
    "\n",
    "# fipstypemap = dict([('fips{:02d}'.format(int(str(x)[2:])),np.dtype('a5')) for x in range(1990,2016)]+\\\n",
    "#               [('naics{:02d}'.format(int(str(x)[2:])),np.dtype('a6')) for x in range(1990,2016)]+\\\n",
    "#               [('sales{:02d}'.format(int(str(x)[2:])),str) for x in range(1990,2016)]+\\\n",
    "#               [('emp{:02d}'.format(int(str(x)[2:])),np.int32) for x in range(1990,2016)])\n",
    "\n",
    "# fipsmap = dict([('fips{:02d}'.format(int(str(x)[2:])),x) for x in range(1990,2016)]+\\\n",
    "#               [('sales{:02d}'.format(int(str(x)[2:])),x) for x in range(1990,2016)]+\\\n",
    "#               [('naics{:02d}'.format(int(str(x)[2:])),x) for x in range(1990,2016)]+\\\n",
    "#               [('emp{:02d}'.format(int(str(x)[2:])),x) for x in range(1990,2016)])\n",
    "# fipstypemap['dunsnumber']=str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load naics to occupation mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load naics-to-soc crosswalk for naics 92 public adm data from PUMS 1-year data\n",
    "\n",
    "naics92_soc_pct = pd.read_csv(os.path.join(INPUT_PATH,'pums_2016_naics92_soc_share.csv'),dtype={'NAICSP_2':str}).rename(columns={'NAICSP_2':'naics_2','soc_x':'occ_code'}).set_index(['naics_2','occ_code']).Total\n",
    "naics92_soc_pct.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define 'overflow' industries at 2 digit level\n",
    "\n",
    "naics_exp={'31': '31-33',\n",
    " '32': '31-33',\n",
    " '33': '31-33',\n",
    " '44': u'44-45',\n",
    " '45': u'44-45',\n",
    " '48': u'48-49',\n",
    " '49': u'48-49'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bay area counties\n",
    "bayareafips_full = {'06001':'Alameda', '06013':'Contra Costa', '06041':'Marin', '06055':'Napa', '06075':'San Francisco', '06081':'San Mateo', '06085':'Santa Clara', '06097':'Sonoma', '06095':'Solano'}\n",
    "\n",
    "bayareamsas={'06001': u'San Francisco-Oakland-Hayward, CA',\n",
    " '06013': u'San Francisco-Oakland-Hayward, CA',\n",
    " '06041': u'San Francisco-Oakland-Hayward, CA',\n",
    " '06055': u'Napa, CA',\n",
    " #'06069': u'San Jose-Sunnyvale-Santa Clara, CA',\n",
    " '06075': u'San Francisco-Oakland-Hayward, CA',\n",
    " #'06077': u'Stockton-Lodi, CA',\n",
    " '06081': u'San Francisco-Oakland-Hayward, CA',\n",
    " '06085': u'San Jose-Sunnyvale-Santa Clara, CA',\n",
    " '06087': u'Santa Cruz-Watsonville, CA',\n",
    " '06095': u'Vallejo-Fairfield, CA',\n",
    " '06097': u'Santa Rosa, CA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load naics sector to occupation crosswalk from OES research estimates, subsetted to CA only\n",
    "naics_to_occ=pd.read_excel(os.path.join(INPUT_PATH,'oes_research_data_2019_naics_to_occ_share_ca.xlsx'),dtype={'naics':str,'occ_code':str})\n",
    "naics_to_occ=naics_to_occ.set_index(['naics','occ_code']).tot_emp\n",
    "naics_to_occ.index=naics_to_occ.index.set_names('naics_2',level=0)\n",
    "naics_to_occ.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naics_to_occ_w_naics_92 = naics_to_occ.append(naics92_soc_pct)#.reset_index(name='tot_emp')\n",
    "naics_to_occ_w_naics_92.name='tot_emp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## load Dingel's (2020) occupational propensities\n",
    "# workfromhomeocc_onet_bls=pd.read_csv('https://raw.githubusercontent.com/jdingel/DingelNeiman-workathome/master/occ_onet_scores/output/occupations_workathome.csv')\n",
    "# workfromhomeocc_onet_bls['OCC_CODE']=workfromhomeocc_onet_bls.onetsoccode.str.split('\\.').apply(lambda x: x[0])\n",
    "# workfromhomeocc_onet_bls=workfromhomeocc_onet_bls.groupby(['OCC_CODE']).teleworkable.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load Dingel's (2020) occupational propensities, from O*NET scoring, and mapped to OES categories\n",
    "\n",
    "# 'https://raw.githubusercontent.com/jdingel/DingelNeiman-workathome/master/onet_to_BLS_crosswalk/output/onet_teleworkable_blscodes.csv')\n",
    "#workfromhomeocc_onet=pd.read_csv(os.path.join(INPUT_PATH,'onet_teleworkable_blscodes.csv'),sep='\\t')\n",
    "workfromhomeocc_onet=pd.read_csv('https://raw.githubusercontent.com/jdingel/DingelNeiman-workathome/master/onet_to_BLS_crosswalk/output/onet_teleworkable_blscodes.csv')\n",
    "workfromhomeocc=workfromhomeocc_onet.set_index('OCC_CODE').teleworkable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the employment data\n",
    "Get from postgres whenever there are query changes. Otherwise, grab from csv made each time postgres is queried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_int = lambda x: pd.to_numeric('{:.0f}'.format(pd.to_numeric(x)),errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## large file - get just a few cols\n",
    "\n",
    "nets = pd.read_csv(os.path.join(NETS_PATH,'nets2015wide.csv'),usecols=['dunsnumber','firstyear','lastyear','fips15','naics15','emp15'],\n",
    "                   na_values=[''])\n",
    "\n",
    "nets = nets.set_index(['dunsnumber','firstyear','lastyear'])\n",
    "nets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffbreaks_5 =[0,25,50,100,250,500,1000,np.inf]\n",
    "difflabels_5 = easylabeler(breaks=diffbreaks_5,currency=False)\n",
    "difflabels_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets_2015=nets.filter(regex='15')\n",
    "nets_2015=nets_2015.loc[nets_2015.fips15.notnull()]\n",
    "nets_2015['naics_2']=nets_2015.naics15.astype(int).apply(lambda x: '{:0<6}'.format(x)).str.slice(0,2)\n",
    "nets_2015['naics_2_desc']=nets_2015.naics_2.map(naicsmap)\n",
    "nets_2015['naics_abag']=nets_2015.naics_2.map(naics_abag)\n",
    "nets_2015['naics_mtc']=nets_2015.naics_2.map(naics_mtc)\n",
    "nets_2015['naics_2']=nets_2015['naics_2'].replace(naics_exp)\n",
    "nets_2015['emp_size_cat']=pd.cut(nets_2015.emp15,bins=diffbreaks_5,labels=difflabels_5)\n",
    "nets_2015['emp_bucket']=pd.cut(nets_2015.emp15,bins=[0,25,np.inf],labels=['0-25 employees','25+ employees'])\n",
    "nets_2015['STCOUNTY']=nets_2015.fips15.astype(int).apply(lambda x: '{:0>5}'.format(x))\n",
    "nets_2015['CBSA']=nets_2015.STCOUNTY.map(bayareamsas)\n",
    "nets_2015=nets_2015[nets_2015.STCOUNTY.isin(bayareafips_full)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic summary by indus\n",
    "nets_2015_by_indus_size=nets_2015.groupby(['CBSA','STCOUNTY','naics_2','naics_2_desc','naics_abag','naics_mtc','emp_bucket']).emp15.sum()\n",
    "nets_2015_by_indus_size.head(5).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge emp data with naics-to-occ crosswalk\n",
    "\n",
    "nets_2015_occ_exp=nets_2015_by_indus_size.reset_index().merge(naics_to_occ_w_naics_92.reset_index(),on=['naics_2'])\n",
    "nets_2015_occ_exp['reg']='Bay Area'\n",
    "\n",
    "## weigh employment by telecommute propensity from Dingel (2020)\n",
    "nets_2015_occ_exp['emp15_occ']=nets_2015_occ_exp.emp15*nets_2015_occ_exp.tot_emp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## codes in NETS data but *not* in the Dingel work from home matrix\n",
    "\n",
    "nets_occ_unmatched=list(set(nets_2015_occ_exp.occ_code)-set(workfromhomeocc.index))\n",
    "#oes_occ_unmatched=list(set(naics_to_occ_w_naics_92.index.get_level_values(1).unique())-set(workfromhomeocc.index))\n",
    "#onet_occ_unmatched=list(set(workfromhomeocc.index)-set(naics_to_occ_w_naics_92.index.get_level_values(1).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_det=soc.loc[soc['Detailed Occupation'].notnull()]\n",
    "soc_det_missing_from_onet_WFH=soc_det[soc_det['Detailed Occupation'].isin(nets_occ_unmatched)].set_index('Detailed Occupation').Description.index\n",
    "\n",
    "## take the codes that do *not* have a wfh flag and assign the most common flag \n",
    "## for occupations in the containing major group. Many of them are \"other xxx\"\n",
    "onet_missing_group_imputed=pd.Series(data=soc_det_missing_from_onet_WFH.str.slice(0,2).map(workfromhomeocc.groupby(lambda x: x[:2]).median()),\n",
    "          index=soc_det_missing_from_onet_WFH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD work from home share\n",
    "nets_2015_occ_exp['wfh_flag']=nets_2015_occ_exp.occ_code.map(workfromhomeocc.append(onet_missing_group_imputed))\n",
    "nets_2015_occ_exp['emp15_wfh']=nets_2015_occ_exp.emp15_occ*nets_2015_occ_exp.wfh_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets_2015_occ_exp.groupby(['emp_bucket'])['emp15_occ','emp15_wfh'].sum().plot(kind='barh',figsize=[8,5])\n",
    "title('Bay Area employment, total and work from home potential\\nSources: Work from home potential from Dingel (2020)\\nIndustry - Occupation matrix from BLS OES 2019 Research Estimates (CA subset)\\nEmployment data from National Establishment Timeseries (NETS) 2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=[8,6])\n",
    "ax=sns.heatmap((nets_2015_occ_exp.groupby(['CBSA','naics_mtc','emp_bucket'])['emp15_wfh'].sum()/\\\n",
    "nets_2015_occ_exp.groupby(['CBSA','naics_mtc','emp_bucket'])['emp15_occ'].sum()).unstack([0]).loc(0)[:,'25+ employees'].reset_index(1,drop=True).T\n",
    ",\n",
    "annot=True,fmt=',.2f',linewidths=.5,cmap=cm.coolwarm,\n",
    "           annot_kws={'fontsize':12})\n",
    "title('Employment susceptible to telecommuniting, using NETS data\\nclassified using Dingel (2020) after mapping industry to occupation data\\nBay Area CBSAs shown')\n",
    "plt.tight_layout()\n",
    "plt.yticks(rotation=0,size=12)\n",
    "plt.xticks(rotation=45,size=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=[8,6])\n",
    "ax=sns.heatmap((nets_2015_occ_exp.groupby(['STCOUNTY','naics_mtc','emp_bucket'])['emp15_wfh'].sum()/\\\n",
    "nets_2015_occ_exp.groupby(['STCOUNTY','naics_mtc','emp_bucket'])['emp15_occ'].sum()).unstack([0]).loc(0)[:,'25+ employees'].reset_index(1,drop=True).T\n",
    ",\n",
    "annot=True,fmt=',.2f',linewidths=.5,cmap=cm.coolwarm,\n",
    "           annot_kws={'fontsize':12})\n",
    "title('Employment susceptible to telecommuniting, using NETS data\\nclassified using Dingel (2020) after mapping industry to occupation data\\nBay Area CBSAs shown')\n",
    "plt.tight_layout()\n",
    "plt.yticks(rotation=0,size=12)\n",
    "plt.xticks(rotation=45,size=12)\n",
    "#savefig(os.path.join(box, 'RHNA/Analyses/equity/divergence_opportunity_corr.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=[8,6])\n",
    "ax=sns.heatmap((nets_2015_occ_exp.groupby(['naics_mtc','emp_bucket'])['emp15_wfh'].sum()/\\\n",
    "nets_2015_occ_exp.groupby(['naics_mtc','emp_bucket'])['emp15_occ'].sum()).unstack(),\n",
    "annot=True,fmt=',.2f',linewidths=.5,cmap=cm.coolwarm,\n",
    "           annot_kws={'fontsize':12})\n",
    "title('Employment susceptible to telecommuniting, using NETS data\\nclassified using Dingel (2020) after mapping industry to occupation data')\n",
    "plt.tight_layout()\n",
    "plt.yticks(rotation=0,size=12)\n",
    "plt.xticks(rotation=45,size=12)\n",
    "#savefig(os.path.join(box, 'RHNA/Analyses/equity/divergence_opportunity_corr.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out spreadsheet with WFH potential share based on industry / occupation and establishment size alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "xl4=pd.ExcelWriter(os.path.join(OUTPUT_PATH,'WFH_By_Sector_V4.xlsx'))\n",
    "\n",
    "## WORK FROM HOME POTENTIAL SHARE, by ESTAB SIZE\n",
    "(nets_2015_occ_exp.groupby(['emp_bucket'])['emp15_wfh'].sum()/\\\n",
    "nets_2015_occ_exp.groupby(['emp_bucket'])['emp15_occ'].sum()).reset_index(name='value').to_excel(xl4,'wfhshare_by_estabsize',index=False,merge_cells=False)\n",
    "\n",
    "## WORK FROM HOME POTENTIAL SHARE, by ESTAB SIZE, SECTOR\n",
    "(nets_2015_occ_exp.groupby(['naics_mtc','emp_bucket'])['emp15_wfh'].sum()/\\\n",
    "nets_2015_occ_exp.groupby(['naics_mtc','emp_bucket'])['emp15_occ'].sum()).unstack(1).to_excel(xl4,'wfhshare_by_estabsize_sector',index=True,merge_cells=False)\n",
    "\n",
    "\n",
    "(nets_2015_occ_exp.groupby(['CBSA','naics_mtc'])['emp15_wfh'].sum()/\\\n",
    "nets_2015_occ_exp.groupby(['CBSA','naics_mtc'])['emp15_occ'].sum()).reset_index(name='share').to_excel(xl4,'wfhshare_by_cbsa_sector',index=False,merge_cells=False)\n",
    "(nets_2015_occ_exp.groupby(['naics_mtc'])['emp15_wfh'].sum()/\\\n",
    "nets_2015_occ_exp.groupby(['naics_mtc'])['emp15_occ'].sum()).reset_index(name='share').to_excel(xl4,'wfhshare_by_sector',index=False,merge_cells=False)\n",
    "(nets_2015_occ_exp.groupby(['STCOUNTY','naics_mtc'])['emp15_wfh'].sum()/\\\n",
    "nets_2015_occ_exp.groupby(['STCOUNTY','naics_mtc'])['emp15_occ'].sum()).reset_index(name='share').to_excel(xl4,'wfhshare_by_county_sector',index=False,merge_cells=False)\n",
    "\n",
    "\n",
    "xl4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add blueprint future employment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_controls=pd.read_csv('https://raw.githubusercontent.com/BayAreaMetro/regional_forecast/master/to_baus/s21/employment_controls_s21.csv',index_col='year')\n",
    "emp_controls.columns=emp_controls.columns.str.lower()\n",
    "emp_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From TAZDATA runid 98 run98_taz_summaries_2035.csv\n",
    "\n",
    "blueprint_emp=pd.DataFrame.from_records(rec.array([(2010, 27545., 561534.,  546126.,  867980.,  818157., 636935.),\n",
    "           (2015, 24894., 583589.,  845713., 1189435., 1003617., 358070.),\n",
    "           (2020, 23104., 582468.,  937856., 1125255., 1050257., 360466.),\n",
    "           (2025, 23333., 544887.,  934923., 1250156., 1061631., 332761.),\n",
    "           (2030, 26113., 578753., 1007199., 1438403., 1213576., 380136.),\n",
    "           (2035, 27156., 581930., 1042373., 1507450., 1281516., 394088.),\n",
    "           (2040, 28148., 590287., 1088409., 1578856., 1351402., 416311.),\n",
    "           (2045, 29151., 598673., 1119571., 1632264., 1418337., 429085.),\n",
    "           (2050, 30120., 607658., 1155572., 1688091., 1485460., 441559.)],\n",
    "          dtype=[(u'year', '<i8'), (u'AGREMPN', '<f8'), (u'MWTEMPN', '<f8'), (u'OTHEMPN', '<f8'), (u'HEREMPN', '<f8'), (u'FPSEMPN', '<f8'), (u'RETEMPN', '<f8')])).set_index('year').filter(regex='EMPN').rename(columns=lambda x: x.lower())\n",
    "blueprint_emp.loc[2035]#.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TM full time employment estimate\n",
    "## from /Users/aolsen/Box/Horizon and Plan Bay Area 2050/Blueprint/Final Blueprint Modeling/Protesting Polar Bears/TelecommuteByWorkLocation_analysis_24p.xlsx\n",
    "## cells ByIncomeByIndustry M2:R7\n",
    "\n",
    "TM_FT=pd.DataFrame.from_records(rec.array([('Q1',  33291.546,  49808.282,  98842.342,  30968.88 , 2580.74 ,  42324.136),\n",
    "           ('Q2',  74088.72 , 121628.982, 200656.95 ,  85819.434, 4939.248, 129655.26 ),\n",
    "           ('Q3',  99513.7  , 187266.69 , 256926.28 , 139319.18 , 5428.02 , 216216.13 ),\n",
    "           ('Q4', 173703.168, 504299.52 , 450134.016, 272695.296, 7471.104, 459472.896)],\n",
    "          dtype=[ (u'HHINC', 'O'), (u'RETEMPN', '<f8'), (u'FPSEMPN', '<f8'), (u'HEREMPN', '<f8'), (u'OTHEMPN', '<f8'), (u'AGREMPN', '<f8'), (u'MWTEMPN', '<f8')])).set_index('HHINC').filter(regex='EMP').stack()\n",
    "\n",
    "FT_SHARE_2015=TM_FT.sum(level=1).sum()/blueprint_emp.loc[2015]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Policy assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLICY_VARIABLE=.6\n",
    "bpjobs2035=blueprint_emp.loc[2035].sum()\n",
    "NETS_TOTAL_2015=nets_2015.emp15.sum()\n",
    "jobs2035_TM_FT=TM_FT.sum().sum()\n",
    "FULLTIME_VARIABLE=jobs2035_TM_FT/bpjobs2035\n",
    "FULLTIME_VARIABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate WFH potential taking into account FT/PT\n",
    "\n",
    "* Above 25 emp establishments\n",
    "* Only full time workers\n",
    "* Only select occupations (per Dingel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: 2035 BP employment times share of workers in 25+ establishments\n",
    "blueprint_emp_25p = blueprint_emp * ESTAB_SIZE.loc[:,'25+ employees']\n",
    "blueprint_emp_25p.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Scale this to the full time share\n",
    "blueprint_emp_25p_FT = blueprint_emp_25p * FULLTIME_VARIABLE\n",
    "blueprint_emp_25p_FT.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Scale to work from home share for large establishments\n",
    "blueprint_emp_25p_FT_WFH = blueprint_emp_25p_FT * LARGE_ESTAB_WFH_SHARE\n",
    "blueprint_emp_25p_FT_WFH.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sector specific shares of large employer jobs\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "ESTAB_SIZE=nets_2015_occ_exp.groupby(['reg','naics_mtc','emp_bucket']).emp15_occ.sum().groupby(level=[0,1]).apply(pct).reset_index(0,drop=True)\n",
    "ESTAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sector-specific work from home share\n",
    "LARGE_ESTAB_WFH_SHARE=(nets_2015_occ_exp.groupby(['naics_mtc','emp_bucket'])['emp15_wfh'].sum().unstack(1)/\\\n",
    "    nets_2015_occ_exp.groupby(['naics_mtc','emp_bucket'])['emp15_occ'].sum().unstack(1))#['25+ employees']\n",
    "LARGE_ESTAB_WFH_SHARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "pd.concat([nets_2015_occ_exp.groupby(['naics_mtc','emp_bucket'])['emp15_wfh'].sum().unstack(1),\n",
    "           nets_2015_occ_exp.groupby(['naics_mtc','emp_bucket'])['emp15_wfh'].sum().unstack(1)/\n",
    "           nets_2015_occ_exp.groupby(['naics_mtc','emp_bucket'])['emp15_occ'].sum().unstack(1)],keys=['Count','Percent'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlout=pd.ExcelWriter('/Users/aolsen/Box/_Data/telecommute/summary.xlsx')\n",
    "\n",
    "nets_2015_occ_exp.groupby(['emp_size_cat'])['emp15_occ','emp15_wfh'].sum().to_excel(xlout,'emp_by_estab_size')\n",
    "\n",
    "nets_2015_occ_exp.groupby(['emp_size_cat','naics_2_desc'])['emp15_occ','emp15_wfh'].sum().unstack(0).to_excel(xlout,'emp_by_naics_by_estab_size')\n",
    "xlout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older stuff (InfoGroup, other miscm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infogroup = pd.read_csv('/Users/aolsen/Box/_Data/BusinessData/BusinessData/BA_CA_2017_gdb_exports/BA_CA_2017_wcounty.csv')\n",
    "infogroup=infogroup[infogroup.County.isin(bayareafips_full.values())]\n",
    "infogroup.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infogroup['emp_size_cat']=pd.cut(infogroup.EMPNUM,bins=diffbreaks_5,labels=difflabels_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "infogroup.groupby(['emp_size_cat']).EMPNUM.sum()/infogroup.groupby(['emp_size_cat']).EMPNUM.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets_2015.groupby(['emp_size_cat']).emp15.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(ncols=1,figsize=[8,5.5],sharey=True,sharex=True)\n",
    "pd.concat([nets_2015.groupby(['emp_size_cat']).emp15.sum(),\n",
    "infogroup.groupby(['emp_size_cat']).EMPNUM.sum()],keys=['NETS','InfoGroup']).unstack(0).plot(kind='bar',ax=axs)\n",
    "title('Firm size distributions, NETS and InfoGroup')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
