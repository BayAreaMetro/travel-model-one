USAGE = """
  python RoadwaysToPeMS_Validation.py -m model_year -p pems_year

 Where pems_year can be specified multiple times

 e.g.  python RoadwaysToPeMS_Validation.py -m 2005 -p 2005 -p 2006 -p 2007

 Creates a Tableau Data Extract for validating roadway volumes compared to PeMS data.

 Input:

 1) model_to_pems.csv: maps model roadway links to PeMS stations
    Required columns: a, b, station, HOV

2) avgload5period.csv: model data
   Required columns: a, b, lanes, volEA_tot, volAM_tot, volMD_tot, volPM_tot, volEV_tot

3) pems_period.csv: PeMS observed data, generated by 
   https://github.com/MetropolitanTransportationCommission/pems-typical-weekday
   Required columns: station, route, direction, time_period, 
                     lanes, median_flow, avg_flow, latitude, longitude, year
Output:

1) Roadways to PeMS.tde: a tableau data extract containing both modeled and observed data.
   Columns:  a, b, station, route, direction, latitude, longitude, lanes, time_period, 
             volume, category
   Where category is one of 'XXXX Modeled' or 'XXXX Observed', with XXXX being the
   relevant year


"""
import getopt
import pandas
import os
import sys
import dataextract as tde

MAPPING_FILE    = "model_to_pems.csv"
MODEL_FILE      = "avgload5period.csv"
PEMS_FILE       = "pems_period.csv"
TDE_FILE        = "Roadways to PeMS.tde"

fieldMap = { 
    'float64' :     tde.Type.DOUBLE,
    'float32' :     tde.Type.DOUBLE,
    'int64' :       tde.Type.DOUBLE,
    'int32' :       tde.Type.DOUBLE,
    'object':       tde.Type.UNICODE_STRING,
    'bool' :        tde.Type.BOOLEAN
}

# 
# from Rdata to TableauExtract.py -- move to library?
# 
def write_tde(table_df, tde_fullpath, arg_append):
    """
    Writes the given pandas dataframe to the Tableau Data Extract given by tde_fullpath
    """
    if arg_append and not os.path.isfile(tde_fullpath):
        print "Couldn't append -- file doesn't exist"
        arg_append = False

    # Remove it if already exists
    if not arg_append and os.path.exists(tde_fullpath):
        os.remove(tde_fullpath)
    tdefile = tde.Extract(tde_fullpath)

    # define the table definition
    table_def = tde.TableDefinition()
    
    # create a list of column names
    colnames = table_df.columns
    # create a list of column types
    coltypes = table_df.dtypes

    # for each column, add the appropriate info the Table Definition
    for col_idx in range(0, len(colnames)):
        cname = colnames[col_idx]
        ctype = fieldMap[str(coltypes[col_idx])]
        table_def.addColumn(cname, ctype)        

    # create the extract from the Table Definition
    if arg_append:
        tde_table = tdefile.openTable('Extract')
    else:
        tde_table = tdefile.addTable('Extract', table_def)
    row = tde.Row(table_def)

    isnull_df = pandas.isnull(table_df)
    # print isnull_df.head()

    for r in range(0, table_df.shape[0]):
        for c in range(0, len(coltypes)):
            try:
                if isnull_df.iloc[r,c]==True:
                    row.setNull(c)
                elif str(coltypes[c]) == 'float64':
                    row.setDouble(c, table_df.iloc[r,c])
                elif str(coltypes[c]) == 'float32':
                    row.setDouble(c, table_df.iloc[r,c])
                elif str(coltypes[c]) == 'int64':
                    row.setDouble(c, table_df.iloc[r,c])   
                elif str(coltypes[c]) == 'int32':
                    row.setDouble(c, table_df.iloc[r,c])
                elif str(coltypes[c]) == 'object':
                    row.setString(c, table_df.iloc[r,c]) 
                elif str(coltypes[c]) == 'bool':
                    row.setBoolean(c, table_df.iloc[r,c])
                else:
                    row.setNull(c)
            except:
                print coltypes[c], colnames[c], table_df.iloc[r,c]
                print table_df.iloc[r,:]
                print isnull_df.iloc[r,:]
                raise

        # insert the row
        tde_table.insert(row)

    tdefile.close()
    print "Wrote %d lines to %s" % (len(table_df), tde_fullpath)

if __name__ == '__main__':

    optlist, args = getopt.getopt(sys.argv[1:], "m:p:", ['model_year=','pems_year='])
    
    arg_model_year      = None
    arg_pems_year       = []
    for opt,arg in optlist:
        if opt in ('-m', '--model_year'):
            arg_model_year = int(arg)
        elif opt in ('-p', '--pems_year'):
            arg_pems_year.append(int(arg))

    if arg_model_year == None:
        print USAGE
        print "No model year argument specified."
        sys.exit(2)

    if len(arg_pems_year) == 0:
        print USAGE
        print "No PeMS year argument specified."
        sys.exit(2)

    ############ read the mapping first
    mapping_df = pandas.read_csv(MAPPING_FILE)

    # strip the column names
    col_rename = {}
    for colname in mapping_df.columns.values.tolist(): col_rename[colname] = colname.strip()
    mapping_df.rename(columns=col_rename, inplace=True)

    ############ read the model data
    model_df = pandas.read_csv(MODEL_FILE)

    # strip the column names
    col_rename = {}
    for colname in model_df.columns.values.tolist(): col_rename[colname] = colname.strip()
    model_df.rename(columns=col_rename, inplace=True)

    # select only the columns we want
    model_df = model_df[['a','b','lanes','volEA_tot','volAM_tot','volMD_tot','volPM_tot','volEV_tot']]
    # create a multi index for stacking
    model_df.set_index(['a','b','lanes'], inplace=True)
    # stack: so now we have a series with multiindex: a,b,lanes,varname
    model_df = pandas.DataFrame({'volume': model_df.stack(5)})
    # reset the index
    model_df.reset_index(inplace=True)
    # and rename it
    model_df.rename(columns={'level_3':'time_period'}, inplace=True)
    # remove extra chars: 'volAM_tot' => 'AM'
    model_df['time_period'] = model_df['time_period'].str[3:5]

    ############ read the pems data
    pems_df = pandas.read_csv(PEMS_FILE, na_values='NA')

    # strip the column names
    col_rename = {}
    for colname in pems_df.columns.values.tolist(): col_rename[colname] = colname.strip()
    pems_df.rename(columns=col_rename, inplace=True)

    # select only the columns we want
    pems_df = pems_df[['station','route','direction','time_period','lanes','avg_flow','latitude','longitude','year']]
    # select only the years in question
    pems_df = pems_df[ pems_df['year'].isin(arg_pems_year)]

    # get just the location information
    pems_location_df = pems_df[['station','route','direction','latitude','longitude']]
    # move NA lat,long to the end... but if the stationn moves, this is kind of silly  
    pems_location_df = pems_location_df.sort(columns=['latitude','longitude'])
    pems_location_df.drop_duplicates(subset='station', inplace=True)
    # add it to the mapping
    mapping_df = pandas.merge(left=mapping_df, right=pems_location_df, how='left')

    # create the final table -- first the model information
    # cols = a, b, station, HOV, route, direction, lat, long, lanes, time_period, volume
    model_final_df = pandas.merge(left=mapping_df, right=model_df, how='inner')
    model_final_df['category'] = '%d Modeled' % arg_model_year

    # create missing cols in PeMS
    pems_df['a'] = -1
    pems_df['b'] = -1
    pems_df['HOV'] = -1
    pems_df.rename(columns={'avg_flow':'volume', 'year':'category'}, inplace=True)
    pems_df['category'] = pems_df.category.map(str) + ' Observed'

    # put them together!
    table_df = model_final_df.append(pems_df)

    # and write it
    # print table_df.head()
    write_tde(table_df, TDE_FILE, arg_append=False)
