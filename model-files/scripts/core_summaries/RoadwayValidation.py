USAGE = """
  python RoadwayValidation.py -m model_year [-p pems_year|-c caltrans_year]

 Where pems_year or caltrans_year can be specified multiple times (but not at the same time)

 e.g.  python RoadwayValidation.py -m 2005 -p 2005 -p 2006 -p 2007

 Creates a Tableau Data Extract for validating roadway volumes compared to PeMS or CalTrans count data.

 Input:
========
1) avgload5period.csv: model data
   Required columns: a, b, lanes, volEA_tot, volAM_tot, volMD_tot, volPM_tot, volEV_tot

If PeMS years specified:

p2) model_to_pems.csv: maps model roadway links to PeMS stations
    Required columns: a, b, station, HOV

p3) pems_period.csv: PeMS observed data, generated by 
    https://github.com/MetropolitanTransportationCommission/pems-typical-weekday
    Required columns: station, route, direction, time_period, 
                      lanes, median_flow, avg_flow, latitude, longitude, year

If CalTrans years specified:

c2) model_to_caltrans.csv: maps model roadway links to CalTrans count locations
    Required columns: a, b, county, route, postmile, direction, leg, description

c3) M:\Data\Traffic\Counts\AnnualSummary\Yr1998_yr2012_CountSummary.csv
    Required columns: STATION, COUNTY, ROUTE, PM, DIR, LEG, DESCRIP, 
      MeanAM1HrXX, MeanPM1HrXX, MeanTot24XX, MeanCount6MorXX, MeanCount4AMPkXX, MeanCount5MidXX, MeanCount4PMPkXX, MeanCount5EveXX,
      

Output:
========

If PeMS years specified:

p1) Roadways to PeMS.tde: a tableau data extract containing both modeled and observed data.
    Columns:  a, b, station, route, direction, latitude, longitude, lanes, time_period, 
              volume, category
    Where category is one of 'XXXX Modeled' or 'XXXX Observed', with XXXX being the
    relevant year


If CalTrans years specified:

"""
import getopt
import numpy
import os
import pandas
import sys
import dataextract as tde

PEMS_MAP_FILE       = "model_to_pems.csv"
CALTRANS_MAP_FILE   = "model_to_caltrans.csv"
MODEL_FILE          = "avgload5period.csv"
PEMS_FILE           = "pems_period.csv"
CALTRANS_FILE       = r"M:\Data\Traffic\Counts\AnnualSummary\Yr1998_yr2012_CountSummary.csv"

PEMS_TDE_FILE       = "Roadways to PeMS"
CALTRANS_TDE_FILE   = "Roadways to Caltrans"

MODEL_COLUMNS       = ['a','b','lanes','volEA_tot','volAM_tot','volMD_tot','volPM_tot','volEV_tot']
PEMS_COLUMNS        = ['station','route','direction','time_period','lanes','avg_flow','latitude','longitude','year']
CALTRANS_COLUMNS    = ['STATION', 'COUNTY', 'ROUTE', 'PM', 'DIR', 'LEG', 'DESCRIP',
                       'MeanTot24', 'MeanCount4AMPk', 'MeanCount5Mid', 'MeanCount4PMPk']

fieldMap = { 
    'float64' :     tde.Type.DOUBLE,
    'float32' :     tde.Type.DOUBLE,
    'int64' :       tde.Type.DOUBLE,
    'int32' :       tde.Type.DOUBLE,
    'object':       tde.Type.UNICODE_STRING,
    'bool' :        tde.Type.BOOLEAN
}

# 
# from Rdata to TableauExtract.py -- move to library?
# 
def write_tde(table_df, tde_fullpath, arg_append):
    """
    Writes the given pandas dataframe to the Tableau Data Extract given by tde_fullpath
    """
    if arg_append and not os.path.isfile(tde_fullpath):
        print "Couldn't append -- file doesn't exist"
        arg_append = False

    # Remove it if already exists
    if not arg_append and os.path.exists(tde_fullpath):
        os.remove(tde_fullpath)
    tdefile = tde.Extract(tde_fullpath)

    # define the table definition
    table_def = tde.TableDefinition()
    
    # create a list of column names
    colnames = table_df.columns
    # create a list of column types
    coltypes = table_df.dtypes

    # for each column, add the appropriate info the Table Definition
    for col_idx in range(0, len(colnames)):
        cname = colnames[col_idx]
        ctype = fieldMap[str(coltypes[col_idx])]
        table_def.addColumn(cname, ctype)        

    # create the extract from the Table Definition
    if arg_append:
        tde_table = tdefile.openTable('Extract')
    else:
        tde_table = tdefile.addTable('Extract', table_def)
    row = tde.Row(table_def)

    isnull_df = pandas.isnull(table_df)
    print isnull_df.head()

    for r in range(0, table_df.shape[0]):
        for c in range(0, len(coltypes)):
            try:
                if isnull_df.iloc[r,c]==True:
                    row.setNull(c)
                elif str(coltypes[c]) == 'float64':
                    row.setDouble(c, table_df.iloc[r,c])
                elif str(coltypes[c]) == 'float32':
                    row.setDouble(c, table_df.iloc[r,c])
                elif str(coltypes[c]) == 'int64':
                    row.setDouble(c, table_df.iloc[r,c])   
                elif str(coltypes[c]) == 'int32':
                    row.setDouble(c, table_df.iloc[r,c])
                elif str(coltypes[c]) == 'object':
                    row.setString(c, str(table_df.iloc[r,c]))
                elif str(coltypes[c]) == 'bool':
                    row.setBoolean(c, table_df.iloc[r,c])
                else:
                    row.setNull(c)
            except:
                print coltypes[c], colnames[c], table_df.iloc[r,c]
                print table_df.iloc[r,:]
                print isnull_df.iloc[r,:]
                raise

        # insert the row
        tde_table.insert(row)

    tdefile.close()
    print "Wrote %d lines to %s" % (len(table_df), tde_fullpath)

if __name__ == '__main__':

    optlist, args = getopt.getopt(sys.argv[1:], "m:c:p:", ['model_year=','caltrans_year=','pems_year='])
    
    arg_model_year      = None
    arg_pems_year       = []
    arg_caltrans_year   = []
    for opt,arg in optlist:
        if opt in ('-m', '--model_year'):
            arg_model_year = int(arg)
        elif opt in ('-p', '--pems_year'):
            arg_pems_year.append(int(arg))
        elif opt in ('-c', '--caltrans_year'):
            arg_caltrans_year.append(int(arg))

    if arg_model_year == None:
        print USAGE
        print "No model year argument specified."
        sys.exit(2)

    if len(arg_pems_year) == 0 and len(arg_caltrans_year) == 0:
        print USAGE
        print "No PeMS year nor CalTrans count year argument specified."
        sys.exit(2)

    if len(arg_pems_year) > 0 and len(arg_caltrans_year) > 0:
        print USAGE
        print "Either PeMS year or CalTrans count year argument must be specified but not both."
        sys.exit(2)

    ############ read the mapping first
    mapping_df = None
    tde_file   = None
    if len(arg_pems_year) > 0:
        mapping_df = pandas.read_csv(PEMS_MAP_FILE)
        tde_file   = PEMS_TDE_FILE
    else:
        mapping_df = pandas.read_csv(CALTRANS_MAP_FILE)
        tde_file   = CALTRANS_TDE_FILE

    # strip the column names
    col_rename = {}
    for colname in mapping_df.columns.values.tolist(): col_rename[colname] = colname.strip()
    mapping_df.rename(columns=col_rename, inplace=True)
    # print mapping_df.head()

    ############ read the model data
    model_df = pandas.read_csv(MODEL_FILE)

    # strip the column names
    col_rename = {}
    for colname in model_df.columns.values.tolist(): col_rename[colname] = colname.strip()
    model_df.rename(columns=col_rename, inplace=True)

    # select only the columns we want
    model_df = model_df[MODEL_COLUMNS]

    # for caltrans, lets make a daily column
    if len(arg_caltrans_year) > 0:
        model_df['Daily'] = model_df[['volEA_tot','volAM_tot','volMD_tot','volPM_tot','volEV_tot']].sum(axis=1)

    # create a multi index for stacking
    model_df.set_index(['a','b','lanes'], inplace=True)
    # stack: so now we have a series with multiindex: a,b,lanes,varname
    model_df = pandas.DataFrame({'volume': model_df.stack(5)})
    # reset the index
    model_df.reset_index(inplace=True)
    # and rename it
    model_df.rename(columns={'level_3':'time_period'}, inplace=True)
    # remove extra chars: 'volAM_tot' => 'AM'
    model_df['time_period'][model_df['time_period']!='Daily'] = model_df['time_period'].str[3:5]

    if len(arg_pems_year) > 0:
        ############ read the pems data
        obs_df = pandas.read_csv(PEMS_FILE, na_values='NA')
    
        # strip the column names
        col_rename = {}
        for colname in obs_df.columns.values.tolist(): col_rename[colname] = colname.strip()
        obs_df.rename(columns=col_rename, inplace=True)
    
        # select only the columns we want
        obs_df = obs_df[PEMS_COLUMNS]
        # select only the years in question
        obs_df = obs_df[ obs_df['year'].isin(arg_pems_year)]
    
        # get just the location information
        pems_location_df = obs_df[['station','route','direction','latitude','longitude']]
        # move NA lat,long to the end... but if the stationn moves, this is kind of silly  
        pems_location_df = pems_location_df.sort(columns=['latitude','longitude'])
        pems_location_df.drop_duplicates(subset='station', inplace=True)
        # add it to the mapping
        mapping_df = pandas.merge(left=mapping_df, right=pems_location_df, how='left')

        # create missing cols in PeMS
        obs_df['HOV'] = -1
        obs_df.rename(columns={'avg_flow':'volume', 'year':'category'}, inplace=True)
        obs_df['category'] = obs_df.category.map(str) + ' Observed'
    else:
        obs_df = pandas.read_csv(CALTRANS_FILE)
        # strip the column names
        col_rename = {}
        for colname in obs_df.columns.values.tolist(): col_rename[colname] = colname.strip()
        obs_df.rename(columns=col_rename, inplace=True)

        # create postmile rounded
        obs_df['POSTMILE_INT'] = numpy.round(obs_df['PM'])

        keep_columns = list(CALTRANS_COLUMNS)
        col_to_yearcols = {}
        for cyear in arg_caltrans_year:
            for count_col in CALTRANS_COLUMNS:
                if count_col[:4] != 'Mean': continue
                # remove originals from keep_columns
                if count_col in keep_columns: keep_columns.remove(count_col)
                # keep track of them indexed by originals
                if count_col not in col_to_yearcols: col_to_yearcols[count_col] = []

                year_count_col = "%s%02d" % (count_col, cyear % 100)
                col_to_yearcols[count_col].append(year_count_col)
                keep_columns.append(year_count_col)

        # get rid of columns we don't care about
        keep_columns.append('POSTMILE_INT')
        print keep_columns
        obs_df = obs_df[keep_columns]

        # add averages across years
        for count_col in col_to_yearcols.keys():
            # e.g. MeanCount4PMPk col = average of MeanCount4PMPk04 MeanCount4PMPk05 MeanCount4PMPk06 cols
            obs_df["%sav" % count_col] = obs_df[col_to_yearcols[count_col]].mean(axis=1)

        # stack the rest
        obs_df.set_index(['STATION','COUNTY','ROUTE','POSTMILE_INT','PM','DIR','LEG','DESCRIP'], inplace=True)
        # stack: so now we have a series with multiindex: of the above
        obs_df = pandas.DataFrame({'volume': obs_df.stack(5)})
        print obs_df

        # reset the index
        obs_df.reset_index(inplace=True)
        # and rename it
        obs_df.rename(columns={'level_8':'time_period'}, inplace=True)
        # pull out the year as an integer
        obs_df['category'] = obs_df['time_period'].str[-2:]
        obs_df['category'][obs_df['category'].str[0]=='0'] = '20'+ obs_df.category.map(str) + ' Observed'
        obs_df['category'][obs_df['category'].str[0]=='9'] = '19'+ obs_df.category.map(str) + ' Observed'
        obs_df['category'][obs_df['category']=='av'] = 'Average Observed'

        obs_df['time_period'] = obs_df['time_period'].str[4:-2]
        print obs_df['time_period'].value_counts()
        obs_df['time_period'][obs_df['time_period']=='Tot24'     ] = 'Daily'
        obs_df['time_period'][obs_df['time_period']=='Count4AMPk'] = 'AM'
        obs_df['time_period'][obs_df['time_period']=='Count5Mid' ] = 'MD'
        obs_df['time_period'][obs_df['time_period']=='Count4PMPk'] = 'PM'
        obs_df['lanes'] = None

        # model needs DESCRIP, STATION
        model_df['PM']      = None
        model_df['DESCRIP'] = None
        model_df['STATION'] = None


    # model has a, b
    obs_df['a'] = -1
    obs_df['b'] = -1

    # create the final stacked table -- first the model information
    model_final_df = pandas.merge(left=mapping_df, right=model_df, how='inner')
    model_final_df['category'] = '%d Modeled' % arg_model_year

    print "Model columns: ", sorted(model_final_df.columns.values.tolist())
    print "Obsrv columns: ", sorted(obs_df.columns.values.tolist())
    # followed by the observed
    table_df = model_final_df.append(obs_df)
    write_tde(table_df, "%s.tde" % tde_file, arg_append=False)

    # CALTRANS - want a "wide" version, with a column for obsy1, obsy2, obsy3, modeled
    # PeMS - we're done
    if len(arg_pems_year) > 0:
        sys.exit(0)

    # create the joined version -- make the categories into columns
    obs_wide = obs_df[['STATION','COUNTY','ROUTE','POSTMILE_INT','PM','DIR','LEG','DESCRIP','time_period','category','volume']]
    # can't have NaNs in the index -- unstack() will error with a bogus thing about duplicate index values
    obs_wide['STATION'].fillna(0, inplace=True)
    # this is the index
    obs_wide.set_index(['STATION','COUNTY','ROUTE','POSTMILE_INT','PM','DIR','LEG','DESCRIP','time_period','category'], inplace=True)

    # unstack it!
    obs_wide = obs_wide.unstack('category')
    obs_wide.reset_index(inplace=True)

    model_wide = model_final_df[['a','b','COUNTY','ROUTE','POSTMILE_INT','DIR','LEG','lanes','time_period','category','volume']]
    model_wide.set_index(['a','b','COUNTY','ROUTE','POSTMILE_INT','DIR','LEG','lanes','time_period','category'], inplace=True)
    model_wide = model_wide.unstack('category')
    model_wide.reset_index(inplace=True)
    model_wide['ROUTE'] = model_wide['ROUTE'].apply(str)

    table_wide = pandas.merge(left=model_wide, right=obs_wide, how='inner')
    # flatten the column names
    newcols = []
    for col in table_wide.columns.values:
        if col[0]=='volume':
            newcols.append(col[1])
        else:
            newcols.append(col[0])
    table_wide.columns = newcols
    write_tde(table_wide, "%s_wide.tde" % tde_file, arg_append=False)